{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 1: Standardized Test Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2019, 64% of graduating students participated in the SAT test ([*source*](https://reports.collegeboard.org/archive/sat-suite-program-results/2019/class-2019-results)), surpassing ACT's 52% participation rate ([*source*](https://www.act.org/content/dam/act/unsecured/documents/National-CCCR-2019.pdf)). \n",
    "\n",
    "In order to remain as the leading provider of college entrace test, The College Board seeks to explore trends in SAT and ACT participation rates in 2017-2019 to identify the reasons for the increase in SAT participation rates since 2017, and recommend strategies on how SAT's popularity and participation rate can be futher increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Background](#Background)\n",
    "- [Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-Data)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SAT and ACT are standardized tests that many colleges and universities in the United States require for their admissions process. This score is used along with other materials such as grade point average (GPA) and essay responses to determine whether or not a potential student will be accepted to the university. Supporters of these standardized tests believe that they provide colleges with a broad yardstick to compare applicants across different states and background.\n",
    " \n",
    "The SAT has two sections of the test: Evidence-Based Reading and Writing and Math ([*source*](https://www.princetonreview.com/college/sat-sections)). The ACT has 4 sections: English, Mathematics, Reading, and Science, with an additional optional writing section ([*source*](https://www.act.org/content/act/en/products-and-services/the-act/scores/understanding-your-scores.html)). They have different score ranges, which you can read more about on their websites or additional outside sources (a quick Google search will help you understand the scores for each test):\n",
    "* [SAT](https://collegereadiness.collegeboard.org/sat)\n",
    "* [ACT](https://www.act.org/content/act/en.html)\n",
    "\n",
    "Until 2012, the SATâ€™s popularity exceeded that of the ACT. However, since then, ACT overtook SAT as the top college exam ([*source*](https://www.washingtonpost.com/blogs/answer-sheet/post/how-act-overtook-sat-as-the-top-college-entrance-exam/2012/09/24/d56df11c-0674-11e2-afff-d6c7f20a83bf_blog.html)). This sparked the College Board to revamp the SAT admission test in March 2016, in an attempt to counter the growing popularity of the ACT. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your Data\n",
    "\n",
    "There are 10 datasets included in the [`data`](./data/) folder for this project. You are required to pick **at least two** of these to complete your analysis. Feel free to use more than two if you would like, or add other relevant datasets you find online.\n",
    "\n",
    "* [`act_2017.csv`](./data/act_2017.csv): 2017 ACT Scores by State\n",
    "* [`act_2018.csv`](./data/act_2018.csv): 2018 ACT Scores by State\n",
    "* [`act_2019.csv`](./data/act_2019.csv): 2019 ACT Scores by State\n",
    "* [`act_2019_ca.csv`](./data/act_2019_ca.csv): 2019 ACT Scores in California by School\n",
    "* [`sat_2017.csv`](./data/sat_2017.csv): 2017 SAT Scores by State\n",
    "* [`sat_2018.csv`](./data/sat_2018.csv): 2018 SAT Scores by State\n",
    "* [`sat_2019.csv`](./data/sat_2019.csv): 2019 SAT Scores by State\n",
    "* [`sat_2019_by_intended_college_major.csv`](./data/sat_2019_by_intended_college_major.csv): 2019 SAT Scores by Intended College Major\n",
    "* [`sat_2019_ca.csv`](./data/sat_2019_ca.csv): 2019 SAT Scores in California by School\n",
    "* [`sat_act_by_college.csv`](./data/sat_act_by_college.csv): Ranges of Accepted ACT & SAT Student Scores by Colleges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datasets used for the analysis\n",
    "\n",
    "A total of 6 datasets will be used:\n",
    "\n",
    "* [`act_2017.csv`](./data/act_2017.csv): 2017 ACT Scores by State\n",
    "* [`act_2018.csv`](./data/act_2018.csv): 2018 ACT Scores by State\n",
    "* [`act_2019.csv`](./data/act_2019.csv): 2019 ACT Scores by State\n",
    "* [`sat_2017.csv`](./data/sat_2017.csv): 2017 SAT Scores by State\n",
    "* [`sat_2018.csv`](./data/sat_2018.csv): 2018 SAT Scores by State\n",
    "* [`sat_2019.csv`](./data/sat_2019.csv): 2019 SAT Scores by State\n",
    "\n",
    "\n",
    "##### 2017 ACT Scores by State\n",
    "Dataset contains a total of 7 columns:\n",
    "- State: One of the States in United States of America\n",
    "- Participation: Participation rate shown in % in a given State\n",
    "- English: Aggregate English score in the given State\n",
    "- Math: Agrregate Math score in the given State\n",
    "- Reading: Aggregate Reading score in the given State\n",
    "- Science: Aggregate Science score in the given State\n",
    "- Composite: Aggregate Composite score: Score is based on an average of English, Math, Reading and Science scores in a given State. ((English + Math + Reading + Science)/4). (Rounded to the nearest whole number)\n",
    "\n",
    "##### 2018 ACT Scores by State &  2019 ACT Scores by State\n",
    "Unlike 2017 ACT dataset which contains 7 columns, 2018 and 2019 ACT dataset only contain a total of 3 columns:\n",
    "- State: One of the States in United States of America\n",
    "- Participation: Participation rate shown in % in a given State\n",
    "- Composite: Aggregate Composite score: Score is based on an average of English, Math, Reading and Science scores in a given State. ((English + Math + Reading + Science)/4). (Rounded to the nearest whole number)\n",
    "\n",
    "State,Participation,Evidence-Based Reading and Writing,Math,Total\n",
    "##### 2017 SAT Scores by State & 2018 SAT Scores by State\n",
    "Dataset contains a total of 5 columns:\n",
    "- State: One of the States in United States of America\n",
    "- Participation: Participation rate shown in % in a given State\n",
    "- Evidence-Based Reading and Writing: (EBRW) Aggregate total score of the Reading Test and the Writing and Language Test in a given State\n",
    "- Math: Aggregate Math score in the given State\n",
    "- Total: Aggregate total score EBRW and Math score of participating students in a given State (EBRW + Math)\n",
    "\n",
    "##### 2019 SAT Scores by State \n",
    "Dataset contains a total of 5 columns:\n",
    "- State: One of the States in United States of America\n",
    "- Participation: Participation rate shown in % in a given State\n",
    "- EBRW: Aggregate total score of the Reading Test and the Writing and Language Test in a given State\n",
    "- Math: Aggregate Math score in the given State\n",
    "- Total: Aggregate total score EBRW and Math score of participating students in a given State (EBRW + Math)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your problem statement and your chosen datasets, spend some time doing outside research on state policies or additional information that might be relevant. Summarize your findings below. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. **Make sure that you cite your sources.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Fill out this cell with outside research or any additional background information that will support your analysis.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Challenges\n",
    "\n",
    "1. Manually calculate mean:\n",
    "\n",
    "    Write a function that takes in values and returns the mean of the values. Create a list of numbers that you test on your function to check to make sure your function works!\n",
    "    \n",
    "    *Note*: Do not use any mean methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.75\n"
     ]
    }
   ],
   "source": [
    "# Code:\n",
    "def cal_mean(num_list):\n",
    "    sum = 0\n",
    "    for i in num_list:\n",
    "        sum += i\n",
    "    return (sum/len(num_list))\n",
    "\n",
    "print(cal_mean([5,7,3,16]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Manually calculate standard deviation:\n",
    "\n",
    "    The formula for standard deviation is below:\n",
    "\n",
    "    $$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "    Where $x_i$ represents each value in the dataset, $\\mu$ represents the mean of all values in the dataset and $n$ represents the number of values in the dataset.\n",
    "\n",
    "    Write a function that takes in values and returns the standard deviation of the values using the formula above. Hint: use the function you wrote above to calculate the mean! Use the list of numbers you created above to test on your function.\n",
    "    \n",
    "    *Note*: Do not use any standard deviation methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7204650534085253"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code:\n",
    "def std_dev(num_list):\n",
    "    n = len(num_list)\n",
    "    mean = cal_mean(num_list)\n",
    "    var = sum((x - mean)**2 for x in num_list) / n\n",
    "    std_dev = var ** 0.5\n",
    "    return std_dev\n",
    "\n",
    "# create a list of data points\n",
    "num_list = [8, 10, 5, 7, 9]\n",
    "std_dev(num_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data cleaning function:\n",
    "    \n",
    "    Write a function that takes in a string that is a number and a percent symbol (ex. '50%', '30.5%', etc.) and converts this to a float that is the decimal approximation of the percent. For example, inputting '50%' in your function should return 0.5, '30.5%' should return 0.305, etc. Make sure to test your function to make sure it works!\n",
    "\n",
    "You will use these functions later on in the project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "def string_percent_to_float(string_percent):\n",
    "    return round(float(string_percent.strip('%'))/100, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 2\n",
    "\n",
    "Part 2 requires knowledge of Pandas, EDA, data cleaning, and data visualization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning\n",
    "\n",
    "Import the datasets that you selected for this project and go through the following steps at a minimum. You are welcome to do further cleaning as you feel necessary:\n",
    "1. Display the data: print the first 5 rows of each dataframe to your Jupyter notebook.\n",
    "2. Check for missing values.\n",
    "3. Check for any obvious issues with the observations (keep in mind the minimum & maximum possible values for each test/subtest).\n",
    "4. Fix any errors you identified in steps 2-3.\n",
    "5. Display the data types of each feature.\n",
    "6. Fix any incorrect data types found in step 5.\n",
    "    - Fix any individual values preventing other columns from being the appropriate type.\n",
    "    - If your dataset has a column of percents (ex. '50%', '30.5%', etc.), use the function you wrote in Part 1 (coding challenges, number 3) to convert this to floats! *Hint*: use `.map()` or `.apply()`.\n",
    "7. Rename Columns.\n",
    "    - Column names should be all lowercase.\n",
    "    - Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`).\n",
    "    - Column names should be unique and informative.\n",
    "8. Drop unnecessary rows (if needed).\n",
    "9. Merge dataframes that can be merged.\n",
    "10. Perform any additional cleaning that you feel is necessary.\n",
    "11. Save your cleaned and merged dataframes as csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning: ACT 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "#Import dataset of 2017 ACT participation and score in the different States\n",
    "act_17 = pd.read_csv('../data/act_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State Participation  English  Math  Reading  Science Composite\n",
       "0  National           60%     20.3  20.7     21.4     21.0      21.0\n",
       "1   Alabama          100%     18.9  18.4     19.7     19.4      19.2\n",
       "2    Alaska           65%     18.7  19.8     20.4     19.9      19.8\n",
       "3   Arizona           62%     18.6  19.8     20.1     19.8      19.7\n",
       "4  Arkansas          100%     18.9  19.0     19.7     19.5      19.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the first 5 rows of data\n",
    "act_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.919231</td>\n",
       "      <td>21.173077</td>\n",
       "      <td>22.001923</td>\n",
       "      <td>21.040385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.332132</td>\n",
       "      <td>1.963602</td>\n",
       "      <td>2.048672</td>\n",
       "      <td>3.151113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>19.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.550000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>21.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.300000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>24.125000</td>\n",
       "      <td>22.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.500000</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         English       Math    Reading    Science\n",
       "count  52.000000  52.000000  52.000000  52.000000\n",
       "mean   20.919231  21.173077  22.001923  21.040385\n",
       "std     2.332132   1.963602   2.048672   3.151113\n",
       "min    16.300000  18.000000  18.100000   2.300000\n",
       "25%    19.000000  19.400000  20.475000  19.900000\n",
       "50%    20.550000  20.900000  21.700000  21.150000\n",
       "75%    23.300000  23.100000  24.125000  22.525000\n",
       "max    25.500000  25.300000  26.000000  24.900000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#act_17.describe() shows that min score of Science is exceptionally low as compared to other scores. \n",
    "act_17.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selects row where science score is 2.3 (which is the min shown)\n",
    "act_17[act_17['Science'] == 2.3]\n",
    "#shows that Maryland Science score in the dataset is 2.3\n",
    "\n",
    "#Reference: https://nces.ed.gov/programs/digest/d18/tables/dt18_226.60.asp, Maryland Science score is 22.2, not 2.3\n",
    "#update Maryland Science score to the correct score: 22.2\n",
    "#act_17.loc[21, 'Science'] = 22.2\n",
    "act_17.loc[(act_17.State == 'Maryland'), 'Science'] = 22.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     object \n",
      " 2   English        52 non-null     float64\n",
      " 3   Math           52 non-null     float64\n",
      " 4   Reading        52 non-null     float64\n",
      " 5   Science        52 non-null     float64\n",
      " 6   Composite      52 non-null     object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Display the data types of each feature\n",
    "act_17.info()\n",
    "#act_17.info() and act_17['Composite'].dtype shows that Composite is an object, and not a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>31%</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>100%</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>31%</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>18%</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>32%</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Florida</td>\n",
       "      <td>73%</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>55%</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>90%</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>38%</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>93%</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>35%</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>23.2</td>\n",
       "      <td>22.3</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>67%</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>22.1</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>73%</td>\n",
       "      <td>21.1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>22.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maine</td>\n",
       "      <td>8%</td>\n",
       "      <td>24.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>28%</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>24.2</td>\n",
       "      <td>22.2</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>29%</td>\n",
       "      <td>25.4</td>\n",
       "      <td>25.3</td>\n",
       "      <td>25.9</td>\n",
       "      <td>24.7</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>29%</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>23.8</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>100%</td>\n",
       "      <td>20.4</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Montana</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>84%</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>100%</td>\n",
       "      <td>16.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>18%</td>\n",
       "      <td>25.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34%</td>\n",
       "      <td>23.8</td>\n",
       "      <td>23.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.2</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>66%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>New York</td>\n",
       "      <td>31%</td>\n",
       "      <td>23.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.9</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>100%</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>98%</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>75%</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>40%</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>23%</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.2</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>21%</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.7</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>100%</td>\n",
       "      <td>17.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>80%</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Texas</td>\n",
       "      <td>45%</td>\n",
       "      <td>19.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Utah</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>29%</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.2</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>29%</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Washington</td>\n",
       "      <td>29%</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>69%</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   State Participation  English  Math  Reading  Science  \\\n",
       "0               National           60%     20.3  20.7     21.4     21.0   \n",
       "1                Alabama          100%     18.9  18.4     19.7     19.4   \n",
       "2                 Alaska           65%     18.7  19.8     20.4     19.9   \n",
       "3                Arizona           62%     18.6  19.8     20.1     19.8   \n",
       "4               Arkansas          100%     18.9  19.0     19.7     19.5   \n",
       "5             California           31%     22.5  22.7     23.1     22.2   \n",
       "6               Colorado          100%     20.1  20.3     21.2     20.9   \n",
       "7            Connecticut           31%     25.5  24.6     25.6     24.6   \n",
       "8               Delaware           18%     24.1  23.4     24.8     23.6   \n",
       "9   District of Columbia           32%     24.4  23.5     24.9     23.5   \n",
       "10               Florida           73%     19.0  19.4     21.0     19.4   \n",
       "11               Georgia           55%     21.0  20.9     22.0     21.3   \n",
       "12                Hawaii           90%     17.8  19.2     19.2     19.3   \n",
       "13                 Idaho           38%     21.9  21.8     23.0     22.1   \n",
       "14              Illinois           93%     21.0  21.2     21.6     21.3   \n",
       "15               Indiana           35%     22.0  22.4     23.2     22.3   \n",
       "16                  Iowa           67%     21.2  21.3     22.6     22.1   \n",
       "17                Kansas           73%     21.1  21.3     22.3     21.7   \n",
       "18              Kentucky          100%     19.6  19.4     20.5     20.1   \n",
       "19             Louisiana          100%     19.4  18.8     19.8     19.6   \n",
       "20                 Maine            8%     24.2  24.0     24.8     23.7   \n",
       "21              Maryland           28%     23.3  23.1     24.2     22.2   \n",
       "22         Massachusetts           29%     25.4  25.3     25.9     24.7   \n",
       "23              Michigan           29%     24.1  23.7     24.5     23.8   \n",
       "24             Minnesota          100%     20.4  21.5     21.8     21.6   \n",
       "25           Mississippi          100%     18.2  18.1     18.8     18.8   \n",
       "26              Missouri          100%     19.8  19.9     20.8     20.5   \n",
       "27               Montana          100%     19.0  20.2     21.0     20.5   \n",
       "28              Nebraska           84%     20.9  20.9     21.9     21.5   \n",
       "29                Nevada          100%     16.3  18.0     18.1     18.2   \n",
       "30         New Hampshire           18%     25.4  25.1     26.0     24.9   \n",
       "31            New Jersey           34%     23.8  23.8     24.1     23.2   \n",
       "32            New Mexico           66%     18.6  19.4     20.4     20.0   \n",
       "33              New York           31%     23.8  24.0     24.6     23.9   \n",
       "34        North Carolina          100%     17.8  19.3     19.6     19.3   \n",
       "35          North Dakota           98%     19.0  20.4     20.5     20.6   \n",
       "36                  Ohio           75%     21.2  21.6     22.5     22.0   \n",
       "37              Oklahoma          100%     18.5  18.8     20.1     19.6   \n",
       "38                Oregon           40%     21.2  21.5     22.4     21.7   \n",
       "39          Pennsylvania           23%     23.4  23.4     24.2     23.3   \n",
       "40          Rhode Island           21%     24.0  23.3     24.7     23.4   \n",
       "41        South Carolina          100%     17.5  18.6     19.1     18.9   \n",
       "42          South Dakota           80%     20.7  21.5     22.3     22.0   \n",
       "43             Tennessee          100%     19.5  19.2     20.1     19.9   \n",
       "44                 Texas           45%     19.5  20.7     21.1     20.9   \n",
       "45                  Utah          100%     19.5  19.9     20.8     20.6   \n",
       "46               Vermont           29%     23.3  23.1     24.4     23.2   \n",
       "47              Virginia           29%     23.5  23.3     24.6     23.5   \n",
       "48            Washington           29%     20.9  21.9     22.1     22.0   \n",
       "49         West Virginia           69%     20.0  19.4     21.2     20.5   \n",
       "50             Wisconsin          100%     19.7  20.4     20.6     20.9   \n",
       "51               Wyoming          100%     19.4  19.8     20.8     20.6   \n",
       "\n",
       "   Composite  \n",
       "0       21.0  \n",
       "1       19.2  \n",
       "2       19.8  \n",
       "3       19.7  \n",
       "4       19.4  \n",
       "5       22.8  \n",
       "6       20.8  \n",
       "7       25.2  \n",
       "8       24.1  \n",
       "9       24.2  \n",
       "10      19.8  \n",
       "11      21.4  \n",
       "12      19.0  \n",
       "13      22.3  \n",
       "14      21.4  \n",
       "15      22.6  \n",
       "16      21.9  \n",
       "17      21.7  \n",
       "18      20.0  \n",
       "19      19.5  \n",
       "20      24.3  \n",
       "21      23.6  \n",
       "22      25.4  \n",
       "23      24.1  \n",
       "24      21.5  \n",
       "25      18.6  \n",
       "26      20.4  \n",
       "27      20.3  \n",
       "28      21.4  \n",
       "29      17.8  \n",
       "30      25.5  \n",
       "31      23.9  \n",
       "32      19.7  \n",
       "33      24.2  \n",
       "34      19.1  \n",
       "35      20.3  \n",
       "36      22.0  \n",
       "37      19.4  \n",
       "38      21.8  \n",
       "39      23.7  \n",
       "40      24.0  \n",
       "41      18.7  \n",
       "42      21.8  \n",
       "43      19.8  \n",
       "44      20.7  \n",
       "45      20.3  \n",
       "46      23.6  \n",
       "47      23.8  \n",
       "48      21.9  \n",
       "49      20.4  \n",
       "50      20.5  \n",
       "51     20.2x  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One of the data in Composite column is wrong (20.2x). Replace it with the right data\n",
    "act_17.loc[(act_17.Composite == '20.2x'), 'Composite'] = 20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing Composite column dtype to float\n",
    "#act_17.Composite.map(lambda composite: float(composite))\n",
    "act_17 = act_17.astype({\"Composite\": float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Participation from % to float using created function\n",
    "act_17['Participation'] = act_17['Participation'].apply(lambda x: string_percent_to_float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     float64\n",
      " 2   English        52 non-null     float64\n",
      " 3   Math           52 non-null     float64\n",
      " 4   Reading        52 non-null     float64\n",
      " 5   Science        52 non-null     float64\n",
      " 6   Composite      52 non-null     float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "act_17.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ACT 2017 dataframe contains a row with national participation rate and averages. Drop data column as it is unnecessary in the analysis\n",
    "act_17.drop(0, inplace = True)\n",
    "\n",
    "#Reset index after national row is removed\n",
    "act_17.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove scores of English, Math, Reading and Science as only Composite scores will be used for the analysis\n",
    "act_17.drop(['English', 'Math', 'Reading', 'Science'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns\n",
    "act_17.rename(columns={'Participation':'Participation_act17', 'Composite':'Composite_act17'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changes made to act_17 datase:\n",
    "\n",
    "- Replaced Maryland's wrong composit score of 2.3 to 22.2 \n",
    "- Replace wrongly entered 20.2x in the composit score column to 20.2\n",
    "- Changed Composite column dtype to float\n",
    "- Changed Participation percentages dtype to float\n",
    "- Drop data English, Math, Reading and Science columns from the act_17 dataframe\n",
    "- Rename participation and composite columns to reflect that these data is related ACT 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning: ACT 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset of 2018 ACT participation and composite score in the different States\n",
    "act_18 = pd.read_csv('../data/act_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>33%</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>66%</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>27%</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  Composite\n",
       "0     Alabama          100%       19.1\n",
       "1      Alaska           33%       20.8\n",
       "2     Arizona           66%       19.2\n",
       "3    Arkansas          100%       19.4\n",
       "4  California           27%       22.7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the first 5 rows of data\n",
    "act_18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.544231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.119417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Composite\n",
       "count  52.000000\n",
       "mean   21.544231\n",
       "std     2.119417\n",
       "min    17.700000\n",
       "25%    19.975000\n",
       "50%    21.300000\n",
       "75%    23.725000\n",
       "max    25.600000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#act_18.describe() shows that min score of Science is exceptionally low as compared to other scores. \n",
    "act_18.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     object \n",
      " 2   Composite      52 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Shows the dtype of each column \n",
    "act_18.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                 Participation  Composite\n",
       "Maine                 7%             24.0         2\n",
       "Alabama               100%           19.1         1\n",
       "Montana               100%           20.0         1\n",
       "Nevada                100%           17.7         1\n",
       "New Hampshire         16%            25.1         1\n",
       "New Jersey            31%            23.7         1\n",
       "New Mexico            67%            19.4         1\n",
       "New York              27%            24.5         1\n",
       "North Carolina        100%           19.1         1\n",
       "North Dakota          98%            20.3         1\n",
       "Ohio                  100%           20.3         1\n",
       "Oklahoma              100%           19.3         1\n",
       "Oregon                42%            21.3         1\n",
       "Pennsylvania          20%            23.5         1\n",
       "Rhode Island          15%            24.2         1\n",
       "South Carolina        100%           18.3         1\n",
       "South Dakota          77%            21.9         1\n",
       "Tennessee             100%           19.6         1\n",
       "Texas                 45%            20.7         1\n",
       "Utah                  100%           20.4         1\n",
       "Vermont               24%            24.1         1\n",
       "Virginia              24%            23.9         1\n",
       "Washington            24%            22.2         1\n",
       "West Virginia         65%            20.3         1\n",
       "Wisconsin             100%           20.5         1\n",
       "Nebraska              100%           20.1         1\n",
       "Missouri              100%           20.0         1\n",
       "Alaska                33%            20.8         1\n",
       "Mississippi           100%           18.6         1\n",
       "Arizona               66%            19.2         1\n",
       "Arkansas              100%           19.4         1\n",
       "California            27%            22.7         1\n",
       "Colorado              30%            23.9         1\n",
       "Connecticut           26%            25.6         1\n",
       "Delaware              17%            23.8         1\n",
       "District of columbia  32%            23.6         1\n",
       "Florida               66%            19.9         1\n",
       "Georgia               53%            21.4         1\n",
       "Hawaii                89%            18.9         1\n",
       "Idaho                 36%            22.3         1\n",
       "Illinois              43%            23.9         1\n",
       "Indiana               32%            22.5         1\n",
       "Iowa                  68%            21.8         1\n",
       "Kansas                71%            21.6         1\n",
       "Kentucky              100%           20.2         1\n",
       "Louisiana             100%           19.2         1\n",
       "Maryland              31%            22.5         1\n",
       "Massachusetts         25%            25.5         1\n",
       "Michigan              22%            24.2         1\n",
       "Minnesota             99%            21.3         1\n",
       "Wyoming               100%           20.0         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Value_counts shows that State \"Maine\" is not unique and it has a duplicated row\n",
    "act_18.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicated row. Considers first value as unique and drop the rest of the same values\n",
    "act_18.drop_duplicates(keep = 'first', inplace = True)\n",
    "act_18.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace 'District of columbia' with 'District of Columbia' to match the names in other datasets\n",
    "act_18.loc[8, 'State'] = 'District of Columbia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Participation from % to float using created string_percent_to_float(string_percent) function\n",
    "act_18['Participation'] = act_18['Participation'].apply(lambda x: string_percent_to_float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns\n",
    "act_18.rename(columns={'Participation':'Participation_act18', 'Composite':'Composite_act18'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changes made to act_2018 datase:\n",
    "- Removed duplicated row of data with State as \"Maine\" and reset index\n",
    "- Changed Participation percentages dtype to float\n",
    "- Replace 'District of columbia' with 'District of Columbia' for dataframe merging purposes\n",
    "- Drop row of data with State 'National' as this data will not be used in the analysis\n",
    "- Rename participation and composite columns to reflect that these data is related ACT 2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning: ACT 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset of 2018 ACT participation and composite score in the different States\n",
    "act_19 = pd.read_csv('../data/act_2019.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>73%</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>23%</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  Composite\n",
       "0     Alabama          100%       18.9\n",
       "1      Alaska           38%       20.1\n",
       "2     Arizona           73%       19.0\n",
       "3    Arkansas          100%       19.3\n",
       "4  California           23%       22.6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the first 5 rows of data\n",
    "act_19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.175487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Composite\n",
       "count  52.000000\n",
       "mean   21.450000\n",
       "std     2.175487\n",
       "min    17.900000\n",
       "25%    19.800000\n",
       "50%    20.950000\n",
       "75%    23.650000\n",
       "max    25.500000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe() shows that min score of Science is exceptionally low as compared to other scores. \n",
    "act_19.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     object \n",
      " 2   Composite      52 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Shows dtype of columns\n",
    "act_19.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Participation from % to float using created string_percent_to_float(string_percent) function\n",
    "act_19['Participation'] = act_19['Participation'].apply(lambda x: string_percent_to_float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ACT 2019 dataframe contains a row with national participation rate and averages. This will not be used, and can be removed.\n",
    "act_19.drop(51, inplace = True)\n",
    "\n",
    "#Reset index after national row is removed\n",
    "act_19.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.38</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.73</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.23</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>0.27</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>0.22</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>0.13</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>0.32</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>0.54</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>0.49</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>0.80</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>0.31</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>0.35</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>0.29</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>0.66</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>0.72</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maine</td>\n",
       "      <td>0.06</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>0.28</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>0.21</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>0.19</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>0.95</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>0.82</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Montana</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>0.14</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>0.63</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>New York</td>\n",
       "      <td>0.22</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>0.96</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.17</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>0.12</td>\n",
       "      <td>24.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>0.78</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>0.75</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Texas</td>\n",
       "      <td>0.39</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Utah</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>0.20</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>0.21</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>0.24</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>0.49</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   State  Participation  Composite\n",
       "0                Alabama           1.00       18.9\n",
       "1                 Alaska           0.38       20.1\n",
       "2                Arizona           0.73       19.0\n",
       "3               Arkansas           1.00       19.3\n",
       "4             California           0.23       22.6\n",
       "5               Colorado           0.27       23.8\n",
       "6            Connecticut           0.22       25.5\n",
       "7               Delaware           0.13       24.1\n",
       "8   District of Columbia           0.32       23.5\n",
       "9                Florida           0.54       20.1\n",
       "10               Georgia           0.49       21.4\n",
       "11                Hawaii           0.80       19.0\n",
       "12                 Idaho           0.31       22.5\n",
       "13              Illinois           0.35       24.3\n",
       "14               Indiana           0.29       22.5\n",
       "15                  Iowa           0.66       21.6\n",
       "16                Kansas           0.72       21.2\n",
       "17              Kentucky           1.00       19.8\n",
       "18             Louisiana           1.00       18.8\n",
       "19                 Maine           0.06       24.3\n",
       "20              Maryland           0.28       22.3\n",
       "21         Massachusetts           0.21       25.5\n",
       "22              Michigan           0.19       24.4\n",
       "23             Minnesota           0.95       21.4\n",
       "24           Mississippi           1.00       18.4\n",
       "25              Missouri           0.82       20.8\n",
       "26               Montana           1.00       19.8\n",
       "27              Nebraska           1.00       20.0\n",
       "28                Nevada           1.00       17.9\n",
       "29         New Hampshire           0.14       25.0\n",
       "30            New Jersey           0.25       24.2\n",
       "31            New Mexico           0.63       19.3\n",
       "32              New York           0.22       24.5\n",
       "33        North Carolina           1.00       19.0\n",
       "34          North Dakota           0.96       19.9\n",
       "35                  Ohio           1.00       20.0\n",
       "36              Oklahoma           1.00       18.9\n",
       "37                Oregon           0.42       21.1\n",
       "38          Pennsylvania           0.17       23.6\n",
       "39          Rhode Island           0.12       24.7\n",
       "40        South Carolina           0.78       18.8\n",
       "41          South Dakota           0.75       21.6\n",
       "42             Tennessee           1.00       19.4\n",
       "43                 Texas           0.39       20.5\n",
       "44                  Utah           1.00       20.3\n",
       "45               Vermont           0.20       24.1\n",
       "46              Virginia           0.21       24.0\n",
       "47            Washington           0.24       22.1\n",
       "48         West Virginia           0.49       20.8\n",
       "49             Wisconsin           1.00       20.3\n",
       "50               Wyoming           1.00       19.8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns\n",
    "act_19.rename(columns={'Participation':'Participation_act19', 'Composite':'Composite_act19'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changes made to act_2019 datase:\n",
    "- Changed Participation percentage to float dtype\n",
    "- Removed row with State 'National' as this data will not be used in the analysis\n",
    "- Rename participation and composite columns to reflect that these data is related ACT 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning: SAT 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset of 2017 ACT participation and score in the different States\n",
    "sat_17 = pd.read_csv('../data/sat_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_17.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_17.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove scores Reading and wrting, and math as only total scores will be used for the analysis\n",
    "sat_17.drop(['Evidence-Based Reading and Writing', 'Math'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Participation from % to float using created string_percent_to_float(string_percent) function\n",
    "sat_17['Participation'] = sat_17['Participation'].apply(lambda x: string_percent_to_float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_17.rename(columns={'Participation':'Participation_sat17', 'Total':'Total_sat17'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes made to sat_2017 datase:\n",
    "- Removed Evidence-Based Reading and Writing and Maths columns as data will not be used in the analysis\n",
    "- Changed Participation percentage to dtype float\n",
    "- Rename participation and total score columns to reflect that these data is related SAT 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning: SAT 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset of 2018 SAT participation and score in the different States\n",
    "sat_18 = pd.read_csv('../data/sat_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_18.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_18.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove scores Reading and wrting, and math as only total scores will be used for the analysis\n",
    "sat_18.drop(['Evidence-Based Reading and Writing', 'Math'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Participation from % to float using created string_percent_to_float(string_percent) function\n",
    "sat_18['Participation'] = sat_18['Participation'].apply(lambda x: string_percent_to_float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_18.rename(columns={'Participation':'Participation_sat18', 'Total':'Total_sat18'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes made to sat_2018 datase:\n",
    "- Removed Evidence-Based Reading and Writing and Maths columnsas these data will not be used in the analysis\n",
    "- Changed Participation percentage dtype to float\n",
    "- Rename participation and total score columns to reflect that these data is related SAT 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning: SAT 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset of 2019 SAT participation and score in the different States\n",
    "sat_19 = pd.read_csv('../data/sat_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_19.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_19.info()\n",
    "#more rows of data than other tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove scores Reading and wrting, and math as only total scores will be used for the analysis\n",
    "sat_19.drop(['EBRW', 'Math'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Puerto Rico and Virgin Islands from SAT 2019 as they are not a State in United States and other datasets did not include these 2 rows of data\n",
    "sat_19.drop([39, 47], inplace = True)\n",
    "\n",
    "#Reset index after national row is removed\n",
    "sat_19.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts Participation from % to float\n",
    "sat_19['Participation Rate'] = sat_19['Participation Rate'].apply(lambda x: string_percent_to_float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "sat_19.rename(columns={'Participation Rate':'Participation_sat19', 'Total':'Total_sat19'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes made to sat_19 dataframe:\n",
    "- Removed EBRW and Writing and Maths columns as these data will not be used in the analysis\n",
    "- Removed Puerto Rico and Virgin Islands as they are not State of USA and this is the only data set that contains these 2 rows of data\n",
    "- Changed Participation percentage to dtype float\n",
    "- Rename participation and total score columns to reflect that these data is related SAT 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(left = act_17,\n",
    "                     right = act_18,\n",
    "                     how = \"right\",\n",
    "                     on = 'State')\n",
    "\n",
    "combined_df = pd.merge(left = combined_df,\n",
    "                     right = act_19,\n",
    "                     how = \"right\",\n",
    "                     on = 'State')\n",
    "\n",
    "combined_df = pd.merge(left = combined_df,\n",
    "                     right = sat_17,\n",
    "                     how = \"right\",\n",
    "                     on = 'State')\n",
    "\n",
    "combined_df = pd.merge(left = combined_df,\n",
    "                     right = sat_18,\n",
    "                     how = \"right\",\n",
    "                     on = 'State')\n",
    "\n",
    "combined_df = pd.merge(left = combined_df,\n",
    "                     right = sat_19,\n",
    "                     how = \"right\",\n",
    "                     on = 'State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('../data/combined_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|State|<i>object</i>|combined_df|A state in United States of America| \n",
    "|Participation_act17|<i>float</i>|combined_df|Participation rate of ACT in 2017| \n",
    "|Composite_act17|<i>float</i>|combined_df|Aggregate composite score of participants, based on the average of English, Math, Reading and Science scores of ACT in 2017| \n",
    "|Participation_act18|<i>float</i>|combined_df|Participation rate of ACT in 2018| \n",
    "|Composite_act18|<i>float</i>|combined_df|Aggregate composite score of participants, based on the average of English, Math, Reading and Science scores of ACT in 2018| \n",
    "|Participation_act19|<i>float</i>|combined_df|Participation rate of ACT in 2019| \n",
    "|Composite_act19|<i>float</i>|combined_df|Aggregate composite score of participants, based on the average of English, Math, Reading and Science scores of ACT in 2019| \n",
    "|Participation_sat17|<i>float</i>|combined_df|Participation rate of SAT in 2017| \n",
    "|Composite_sat17|<i>float</i>|combined_df|Aggregate total score of participants, based on total score of Evidenced Based Reading and Writing (EBRW) component and Math of SAT in 2017| \n",
    "|Participation_sat18|<i>float</i>|combined_df|Participation rate of SAT in 2018| \n",
    "|Composite_sat18|<i>float</i>|combined_df|Aggregate total score of participants, based on total score of Evidenced Based Reading and Writing (EBRW) component and Math of SAT in 2018| \n",
    "|Participation_sat19|<i>float</i>|combined_df|Participation rate of SAT in 2019| \n",
    "|Composite_sat19|<i>float</i>|combined_df|Aggregate total score of participants, based on total score of Evidenced Based Reading and Writing (EBRW) component and Math of SAT in 2019|\n",
    "|State|<i>object</i>|change_in_par|A state in United States of America| \n",
    "|Participation_sat17|<i>float</i>|change_in_par|Participation rate of SAT in 2017| \n",
    "|Participation_sat18|<i>float</i>|change_in_par|Participation rate of SAT in 2018| \n",
    "|Participation_sat19|<i>float</i>|change_in_par|Participation rate of SAT in 2019| \n",
    "|Participation_act17|<i>float</i>|change_in_par|Participation rate of ACT in 2017| \n",
    "|Participation_act18|<i>float</i>|change_in_par|Participation rate of ACT in 2018| \n",
    "|Participation_act19|<i>float</i>|change_in_par|Participation rate of ACT in 2019|\n",
    "|Par_change_sat17to19|<i>float</i>|change_in_par|Change in participation rate in SAT from 2017 to 2019| \n",
    "|Par_change_act17to19|<i>float</i>|change_in_par|Change in participation rate in ACT from 2017 to 2019| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Complete the following steps to explore your data. You are welcome to do more EDA than the steps outlined here as you feel necessary:\n",
    "1. Summary Statistics.\n",
    "2. Use a **dictionary comprehension** to apply the standard deviation function you create in part 1 to each numeric column in the dataframe.  **No loops**.\n",
    "    - Assign the output to variable `sd` as a dictionary where: \n",
    "        - Each column name is now a key \n",
    "        - That standard deviation of the column is the value \n",
    "        - *Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`\n",
    "3. Investigate trends in the data.\n",
    "    - Using sorting and/or masking (along with the `.head()` method to avoid printing our entire dataframe), consider questions relevant to your problem statement. Some examples are provided below (but feel free to change these questions for your specific problem):\n",
    "        - Which states have the highest and lowest participation rates for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Which states have the highest and lowest mean total/composite scores for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "        - Do any states show have >50% participation on *both* tests each year?\n",
    "        - Which colleges have the highest median SAT and ACT scores for admittance?\n",
    "        - Which California school districts have the highest and lowest mean test scores?\n",
    "    - **You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "\n",
    "Transpose the output of pandas describe method for the summary statistics of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = combined_df.describe()\n",
    "summary_stats.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Comprehension\n",
    "\n",
    "Use a **dictionary comprehension** to apply the standard deviation function you create in part 1 to each numeric column in the dataframe.  **No loops**.\n",
    "    - Assign the output to variable `sd` as a dictionary where: \n",
    "        - Each column name is now a key \n",
    "        - That standard deviation of the column is the value \n",
    "        - *Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Code:\n",
    "# taking out the 'state' column\n",
    "std_df = combined_df[combined_df.columns[1:12]]\n",
    "\n",
    "#Dictionary comprehension to apply the standard deviation function created to each numeric column in the dataframe\n",
    "std = {x: std_dev(std_df[x]) for x in std_df.columns}\n",
    "\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show standard deviation of selected numeric column in dataframe\n",
    "np.std(combined_df.Participation_act17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate trends in the data\n",
    "Using sorting and/or masking (along with the `.head()` method to avoid printing our entire dataframe), consider questions relevant to your problem statement. Some examples are provided below (but feel free to change these questions for your specific problem):\n",
    "   - Which states have the highest and lowest participation rates for the 2017, 2018, or 2019 SAT and ACT?\n",
    "   - Which states have the highest and lowest mean total/composite scores for the 2017, 2018, or 2019 SAT and ACT?\n",
    "   - Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "   - Do any states show have >50% participation on *both* tests each year?\n",
    "   - Which colleges have the highest median SAT and ACT scores for admittance?\n",
    "   - Which California school districts have the highest and lowest mean test scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States with the highest participation rates for ACT in 2017, 2018 and 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show State ACT participation rates in the 3 years.\n",
    "#Will also keep sat participation rates in the last 3 columns for comparison purposes\n",
    "act_par = combined_df.loc[:,['State','Participation_act17', 'Participation_act18', 'Participation_act19',\n",
    "                            'Participation_sat17', 'Participation_sat18', 'Participation_sat19']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with highest participation rates for ACT sorted by participation rate in 2017\n",
    "act_highest_par_17 = act_par.sort_values(by=['Participation_act17'], ascending=False).head(10)\n",
    "act_highest_par_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with highest participation rates for ACT sorted by participation rate in 2018\n",
    "act_highest_par_18 = act_par.sort_values(by=['Participation_act18'], ascending=False).head(10)\n",
    "act_highest_par_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with highest participation rates for ACT sorted by participation rate in 2019\n",
    "act_highest_par_19 = act_par.sort_values(by=['Participation_act19'], ascending=False).head(10)\n",
    "act_highest_par_19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, based on above result for States with top 10 participation rate for ACT in all 3 years, there seems to be other states with 100% participation rate. These states should also be listed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all States with 100% partipation rate for ACT in 2017, 2018 or 2019\n",
    "act_100_par = act_par[(act_par.Participation_act17 == 1) | (act_par.Participation_act18 == 1) | (act_par.Participation_act19 == 1)]\n",
    "act_100_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of States with 100% participation rate for ACT in at least one of the 3 years\n",
    "print('There are', len(act_100_par), 'States with 100% participation rate for ACT in at least 1 of the 3 years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year-to-year rate changes for States with 100% participation rate for ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_100_par.sort_values(by=['Participation_act19'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_100par_yoy = act_100_par\n",
    "act_100par_yoy['Yoy_act17to18'] = act_100par_yoy['Participation_act18'] - act_100par_yoy['Participation_act17']\n",
    "act_100par_yoy['Yoy_act18to19'] = act_100par_yoy['Participation_act19'] - act_100par_yoy['Participation_act18']\n",
    "act_100par_yoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above result shows the YOY (Year on year) participation rate changes for ACT in States with 100% participation rate in one of the years from 2017 to 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOY Change in 2017 to 2018 in participation rates:\n",
    "- <b>Colorado: </b> `-70%`\n",
    "- <b>Minnesota: </b> `-1%`\n",
    "- <b>Ohio: </b>`+25%%`\n",
    "\n",
    "YOY Change in 2018 to 2019 in participation rates:\n",
    "- <b>Colorado: </b> `-3%`\n",
    "- <b>Minnesota: </b> `-4%`\n",
    "- <b>Missouri: </b> `-18%`\n",
    "- <b>South Carolina: </b>`-22%`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States with the lowest participation rates for ACT in 2017, 2018 and 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with lowest participation rates for ACT sorted by participation rate in 2017\n",
    "act_lowest_par_17 = act_par.sort_values(by=['Participation_act17'], ascending = True).head(10)\n",
    "act_lowest_par_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with lowest participation rates for ACT sorted by participation rate in 2018\n",
    "act_lowest_par_18 = act_par.sort_values(by=['Participation_act18'], ascending = True).head(10)\n",
    "act_lowest_par_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with lowest participation rates for ACT sorted by participation rate in 2019\n",
    "act_lowest_par_19 = act_par.sort_values(by=['Participation_act19'], ascending = True).head(10)\n",
    "act_lowest_par_19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States with the highest participation rates for SAT in 2017, 2018 and 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show State SAT participation rates in the 3 years. \n",
    "#Will show ACT participation rate in the back columns for comparison purposes\n",
    "sat_par = combined_df.loc[:,['State','Participation_sat17', 'Participation_sat18', 'Participation_sat19', \n",
    "                             'Participation_act17', 'Participation_act18', 'Participation_act19']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with highest participation rates for SAT sorted by participation rate in 2017\n",
    "sat_highest_par_17 = sat_par.sort_values(by=['Participation_sat17'], ascending=False).head(10)\n",
    "sat_highest_par_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with highest participation rates for SAT sorted by participation rate in 2018\n",
    "sat_highest_par_18 = sat_par.sort_values(by=['Participation_sat18'], ascending=False).head(10)\n",
    "sat_highest_par_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with highest participation rates for SAT sorted by participation rate in 2019\n",
    "sat_highest_par_19 = sat_par.sort_values(by=['Participation_sat19'], ascending=False).head(10)\n",
    "sat_highest_par_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all States with 100% partipation rate for SAT in 2017, 2018 or 2019\n",
    "sat_100_par = sat_par[(sat_par.Participation_sat17 == 1) | (sat_par.Participation_sat18 == 1) | (sat_par.Participation_sat19 == 1)]\n",
    "sat_100_par "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of States with 100% participation rate for SAT in at least one of the 3 years\n",
    "print('There are', len(sat_100_par), 'States with 100% participation rate for SAT in at least 1 of the 3 years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year-to-year rate changes for States with 100% participation rate for SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_100_par.sort_values(by=['Participation_sat17'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_100par_yoy = sat_100_par\n",
    "sat_100par_yoy['Yoy_sat17to18'] = sat_100par_yoy['Participation_sat18'] - sat_100par_yoy['Participation_sat17']\n",
    "sat_100par_yoy['Yoy_sat18to19'] = sat_100par_yoy['Participation_sat19'] - sat_100par_yoy['Participation_sat18']\n",
    "sat_100par_yoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above result shows the YOY (Year on year) participation rate changes for SAT in States with 100% participation rate in one of the years from 2017 to 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOY Change in 2017 to 2018 in participation rates:\n",
    "- <b>District of Columbia: </b> `-8%`\n",
    "- <b>Idaho: </b>`+7%`\n",
    "- <b>Florida: </b> `-27%`\n",
    "- <b>Rhode Island: </b> `+26%`\n",
    "- <b>Colorado: </b> `-89%`\n",
    "- <b>Illinois: </b> `-90%`\n",
    "\n",
    "YOY Change in 2018 to 2019 in participation rates:\n",
    "- <b>District of Columbia: </b> `+2%`\n",
    "- <b>Florida: </b> `+44%`\n",
    "- <b>Rhode Island: </b>`+3%`\n",
    "- <b>Illinois: </b>`+1%`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States with the lowest participation rates for SAT in 2017, 2018 and 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with lowest participation rates for SAT sorted by participation rate in 2017\n",
    "sat_lowest_par_17 = sat_par.sort_values(by=['Participation_sat17'], ascending = True).head(10)\n",
    "sat_lowest_par_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with lowest participation rates for SAT sorted by participation rate in 2018\n",
    "sat_lowest_par_18 = sat_par.sort_values(by=['Participation_sat18'], ascending = True).head(10)\n",
    "sat_lowest_par_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show top 10 States with lowest participation rates for SAT sorted by participation rate in 2019\n",
    "sat_lowest_par_19 = sat_par.sort_values(by=['Participation_sat19'], ascending = True).head(10)\n",
    "sat_lowest_par_19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### States with >50% participation rate for both ACT and SAT test in 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show States that have more than 50% participation rate in both tests in 2017\n",
    "par50 = combined_df[['State','Participation_sat17','Participation_act17']]\n",
    "\n",
    "par50[(par50['Participation_sat17'] > 0.5) & (par50['Participation_act17'] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show States that have more than 50% participation rate in both tests in 2018\n",
    "par50 = combined_df[['State','Participation_sat18','Participation_act18']]\n",
    "\n",
    "par50[(par50['Participation_sat18'] > 0.5) & (par50['Participation_act18'] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show States that have more than 50% participation rate in both tests in 2019\n",
    "par50 = combined_df[['State','Participation_sat19','Participation_act19']]\n",
    "\n",
    "par50[(par50['Participation_sat19'] > 0.5) & (par50['Participation_act19'] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tennessee = combined_df[['State','Participation_sat17','Participation_act17',\n",
    "                         'Participation_sat18','Participation_act18',\n",
    "                         'Participation_sat19','Participation_act19']]\n",
    "tennessee[(tennessee['State'] == 'Tennessee')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = combined_df[['State','Participation_sat17','Participation_act17',\n",
    "                     'Participation_sat18','Participation_act18',\n",
    "                     'Participation_sat19','Participation_act19']]\n",
    "\n",
    "state[(state['State'] == 'Tennessee')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = combined_df[['State','Participation_sat17','Participation_act17',\n",
    "                     'Participation_sat18','Participation_act18',\n",
    "                     'Participation_sat19','Participation_act19']]\n",
    "\n",
    "state[(state['State'] == 'Idaho') | (state['State'] == 'Ohio') | (state['State'] == 'Tennessee')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit this cell with your findings on trends in the data (step 3 above).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers. It is important to not only create visualizations, but to **interpret your visualizations** as well.\n",
    "\n",
    "**Every plot should**:\n",
    "- Have a title\n",
    "- Have axis labels\n",
    "- Have appropriate tick labels\n",
    "- Text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Have an interpretation to aid understanding\n",
    "\n",
    "Here is an example of what your plots should look like following the above guidelines. Note that while the content of this example is unrelated, the principles of visualization hold:\n",
    "\n",
    "![](https://snag.gy/hCBR1U.jpg)\n",
    "*Interpretation: The above image shows that as we increase our spending on advertising, our sales numbers also tend to increase. There is a positive correlation between advertising spending and sales.*\n",
    "\n",
    "---\n",
    "\n",
    "Here are some prompts to get you started with visualizations. Feel free to add additional visualizations as you see fit:\n",
    "1. Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features.\n",
    "    - Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "    - Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative).\n",
    "2. Visualize distributions using histograms. If you have a lot, consider writing a custom function and use subplots.\n",
    "    - *OPTIONAL*: Summarize the underlying distributions of your features (in words & statistics)\n",
    "         - Be thorough in your verbal description of these distributions.\n",
    "         - Be sure to back up these summaries with statistics.\n",
    "         - We generally assume that data we sample from a population will be normally distributed. Do we observe this trend? Explain your answers for each distribution and how you think this will affect estimates made from these data.\n",
    "3. Plot and interpret boxplots. \n",
    "    - Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "    - Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "    - Each boxplot should:\n",
    "        - Only include variables of a similar scale\n",
    "        - Have clear labels for each variable\n",
    "        - Have appropriate titles and labels\n",
    "4. Plot and interpret scatter plots to view relationships between features. Feel free to write a custom function, and subplot if you'd like. Functions save both time and space.\n",
    "    - Your plots should have:\n",
    "        - Two clearly labeled axes\n",
    "        - A proper title\n",
    "        - Colors and symbols that are clear and unmistakable\n",
    "5. Additional plots of your choosing.\n",
    "    - Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Correlations with seaborn's heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for correlation checking\n",
    "data = ['Participation_sat17', 'Participation_sat18', 'Participation_sat19',\n",
    "        'Total_sat17', 'Total_sat18', 'Total_sat19', \n",
    "        'Participation_act17', 'Participation_act18', 'Participation_act19',\n",
    "        'Composite_act17', 'Composite_act18', 'Composite_act19']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set figure size\n",
    "plt.figure(figsize = (15, 10))\n",
    "\n",
    "corr = combined_df[data].corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "plt.title('Correlation of SAT and ACT Participation Rate and Test Scores', fontsize = 15)\n",
    "\n",
    "heatmap = sns.heatmap(corr,\n",
    "            mask = mask,\n",
    "            cmap = 'coolwarm',\n",
    "            annot = True)\n",
    "\n",
    "#Grouping together the participation rates and scores of each test, will give a better view of the correlations  \n",
    "heatmap.set_xticklabels(['SAT 2017 Participation', 'SAT 2018 Participation', 'SAT 2019 Participation',\n",
    "                         'SAT 2017 Score', 'SAT 2018 Score', 'SAT 2019 Score',\n",
    "                         'ACT 2017 Participation', 'ACT 2018 Participation', 'ACT 2019 Participation',\n",
    "                         'ACT 2017 Score', 'ACT 2018 Score', 'ACT 2019 Score'], fontsize = 12, rotation = 50)\n",
    "\n",
    "heatmap.set_yticklabels(['SAT 2017 Participation', 'SAT 2018 Participation', 'SAT 2019 Participation',\n",
    "                         'SAT 2017 Score', 'SAT 2018 Score', 'SAT 2019 Score',\n",
    "                         'ACT 2017 Participation', 'ACT 2018 Participation', 'ACT 2019 Participation',\n",
    "                         'ACT 2017 Score', 'ACT 2018 Score', 'ACT 2019 Score'], fontsize = 12)\n",
    "\n",
    "plt.savefig('../charts/Heatmap.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretations\n",
    "1. There is a positive correlation between the different years in participation rate / scores for each test.\n",
    "2. There is a positive correlation between SAT participation rate and ACT scores, and vice versa. However, this positive correlation is not strong as they are not really related. \n",
    "3. Interestingly, for each given test, there is a negative correlation between the participation rate and the test scores, meaning that the higher the participation rates, the lower the scores.\n",
    "4. There is a inverse correlation between SAT and ACT participation rate, meaning to say that as the participation rate of one test goes up, the participation rate of the other will decrease.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize distributions using histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subplot histogram function\n",
    "def hist_subplot(df, p_list, title_list):\n",
    "    nrows = int(np.ceil(len(p_list)/2)) \n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2, figsize=(15,15)) #specify figsize\n",
    "    ax = ax.ravel() # Ravel turns a matrix into a vectorto make it easier to iterate\n",
    "    plt.subplots_adjust(hspace = 0.5) #sets height space between charts\n",
    "    for i, column in enumerate(p_list): # Gives an index value to get into all our lists\n",
    "        ax[i].hist(df[column], bins = 10, edgecolor = 'k') # plot histogram subplots with bins = 10\n",
    "        ax[i].vlines(x = np.median(combined_df[p_list[i]]), ymin = 0, ymax = 20, \n",
    "                     linestyle = 'dashed', color = 'salmon', linewidth = 3, label = 'Median')\n",
    "        ax[i].legend(loc = 'upper right', fontsize = 12) # Set legend fpr each subplot\n",
    "        ax[i].axis([0, 1, 0, 23]) # Set x-axis and y-axis values\n",
    "        ax[i].set_title(title_list[i]) # Set titles for each subplot\n",
    "        ax[i].set_xlabel('Participation Rate') # Set xlabels for each subplot\n",
    "        ax[i].set_ylabel('No. of States') # Set xlabels for each subplot\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Participation_sat17'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partipation rate of SAT and ACT from 2017 to 2019\n",
    "p_list = ['Participation_sat17', \n",
    "          'Participation_act17', \n",
    "          'Participation_sat18', \n",
    "          'Participation_act18', \n",
    "          'Participation_sat19', \n",
    "          'Participation_act19']\n",
    "\n",
    "title_list = ['SAT Participation Rate (2017)', \n",
    "              'ACT Participation Rate (2017)', \n",
    "              'SAT Participation Rate (2018)',\n",
    "              'ACT Participation Rate (2018)', \n",
    "              'SAT Participation Rate (2019)', \n",
    "              'ACT Participation Rate (2019)']\n",
    "\n",
    "\n",
    "hist_subplot(combined_df, \n",
    "             p_list,\n",
    "             title_list)\n",
    "\n",
    "plt.savefig('../charts/Histogram.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretations\n",
    "1. Distribution of participation rate for each given test is similar across the 3 years. \n",
    "2. SAT has a higher number of states with very low participation rate, while ACT has a higher number of states with 100% participation rate. The histograms show that the higher number of 100% participation rates in ACT, the higher number of low participation rates in SAT.\n",
    "4. SAT has an increase in the number of states with 100% participation rate in 2019, while ACT has seen a decrease in the number of states with 100% participation rate.\n",
    "5. The median for SAT participation rate has increased over the years, as indicated by the shift in the median line towards the right. The opposite is true for ACT. This shows that participation rate for SAT has increased over the years, while participation rate for ACT has decreased. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of participation rates\n",
    "p_list = ['Participation_sat17', \n",
    "          'Participation_sat18', \n",
    "          'Participation_sat19', \n",
    "          'Participation_act17', \n",
    "          'Participation_act18',\n",
    "          'Participation_act19']\n",
    "\n",
    "plt.figure(figsize = [15, 12]) \n",
    "boxplot = sns.boxplot(data = combined_df[p_list], palette = 'YlGnBu', orient = 'h', width = 0.6) # plotting the boxplot of Participation Rate\n",
    "plt.title('SAT and ACT Participation Rate (2017 to 2019)', fontsize = 16)\n",
    "\n",
    "boxplot.set_yticklabels(['SAT 2017', 'SAT 2018', 'SAT 2019', 'ACT 2017', 'ACT 2018', 'ACT 2019'], fontsize = 12); \n",
    "plt.xticks(fontsize = 12)\n",
    "plt.xlabel('Participation Rate', fontsize = 14)\n",
    "plt.ylabel('Test (Year)', fontsize = 14)\n",
    "\n",
    "plt.savefig('../charts/Boxplot.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretations\n",
    "\n",
    "1. The boxplot as above confirms the interpretation from the histogram charts that SAT's participation rate has been going up since 2017, with an increase in the median participation rate.\n",
    "2. The opposite is true, with ACT's median participation rate going down over the years. However, despite lowered median participation rate, ACT is more popular among states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret scatter plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subplot scatter function\n",
    "def scatter_subplot(df, col_list, columns, t_list, xlabel_list, ylabel_list):\n",
    "    nrows = int(np.ceil(len(col_list))) # Makes sure you have enough rows\n",
    "    fig, ax = plt.subplots(nrows = nrows, ncols = 1, figsize = (15, 20)) # You'll want to specify your figsize\n",
    "    ax = ax.ravel() # Ravel turns a matrix into a vector, which is easier to iterate\n",
    "    \n",
    "    for i, ax in enumerate(ax): # Gives us an index value to get into all our lists\n",
    "        ax.scatter(df[col_list[i]], df[columns[i]]) # need 2 sets of columns for scatter plots\n",
    "        ax.plot([0,1], [1,0], color='maroon', linestyle = 'dotted', label = 'Correlation')\n",
    "        ax.set_title(t_list[i], fontsize = 15) #Set title for each subplot\n",
    "        ax.set_xlabel(xlabel_list[i], fontsize = 12) #Set xlabel for each subplot\n",
    "        ax.set_ylabel(ylabel_list[i], fontsize = 12) #Set ylabel for each subplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_list = ['SAT vs ACT Participation Rate (2017)',\n",
    "          'SAT vs ACT Participation Rate (2018)',\n",
    "          'SAT vs ACT Participation Rate (2019)']\n",
    "\n",
    "xaxis =  ['Participation_sat17',\n",
    "          'Participation_sat18',\n",
    "          'Participation_sat19']\n",
    "\n",
    "yaxis = ['Participation_act17',\n",
    "         'Participation_act18',\n",
    "         'Participation_act19']\n",
    "\n",
    "xlabel = ['SAT Participation Rate (2017)', \n",
    "          'SAT Participation Rate (2018)',\n",
    "          'SAT Participation Rate (2019)']\n",
    "\n",
    "ylabel = ['ACT Participation Rate (2017)', \n",
    "          'ACT Participation Rate (2018)',\n",
    "          'ACT Participation Rate (2019)']\n",
    "\n",
    "scatter_subplot(combined_df, xaxis, yaxis, t_list, xlabel, ylabel)\n",
    "\n",
    "plt.savefig('../charts/Scatter_plot.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Interpretations\n",
    "1.  As with what is shown on the heatmap, the scatter plot shows that the participation rate for SAT and ACT is negatively correlated. \n",
    "2. However, there seems to be some outliers, which does not show any relationships between each other. This can be explained as: Although the participation rate for ACT in States like North and South Carolina is 100%, the participa1tion rate in these 2 states is more than 50%. (as shown in the result below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#List all States with 100% partipation rate for ACT in 2017, 2018 or 2019\n",
    "act_100_par = act_par[(act_par.Participation_act17 == 1) | \n",
    "                      (act_par.Participation_act18 == 1) | \n",
    "                      (act_par.Participation_act19 == 1)]\n",
    "act_100_par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize using Bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participations = combined_df.pivot_table(index=['State'],\n",
    "                                  values=['Participation_sat17','Participation_act17'])\n",
    "participations.sort_values('Participation_sat17', ascending = True, inplace = True)\n",
    "participations.plot(kind='barh', figsize=(14,12))\n",
    "plt.title('SAT vs ACT Participation Rate (2017)', fontsize = 16)\n",
    "plt.xlabel('Participation Rate', fontsize = 14)\n",
    "plt.ylabel('State', fontsize = 14)\n",
    "objects = ('ACT', 'SAT')\n",
    "y_pos = np.arange(len(objects))\n",
    "# add the legend\n",
    "plt.legend(labels=objects, loc = 'lower right', framealpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participations = combined_df.pivot_table(index=['State'],\n",
    "                                  values=['Participation_sat18','Participation_act18'])\n",
    "participations.sort_values('Participation_sat18', ascending = True, inplace = True)\n",
    "participations.plot(kind='barh', figsize=(14,12))\n",
    "plt.title('SAT vs ACT Participation Rate (2018)', fontsize = 16)\n",
    "plt.xlabel('Participation Rate', fontsize = 14)\n",
    "plt.ylabel('State', fontsize = 14)\n",
    "objects = ('ACT', 'SAT')\n",
    "y_pos = np.arange(len(objects))\n",
    "# add the legend\n",
    "plt.legend(labels=objects, loc = 'lower right', framealpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participations = combined_df.pivot_table(index=['State'],\n",
    "                                  values=['Participation_sat19','Participation_act19'])\n",
    "participations.sort_values('Participation_sat19', ascending = True, inplace = True)\n",
    "participations.plot(kind='barh', figsize=(14,12))\n",
    "plt.title('SAT vs ACT Participation Rate (2019)', fontsize = 16)\n",
    "plt.xlabel('Participation Rate', fontsize = 14)\n",
    "plt.ylabel('State', fontsize = 14)\n",
    "objects = ('ACT', 'SAT')\n",
    "y_pos = np.arange(len(objects))\n",
    "# add the legend\n",
    "plt.legend(labels=objects, loc = 'lower right', framealpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change in Participation Rate from 2017 to 2019\n",
    "\n",
    "change_in_par = combined_df.loc[:,['State', 'Participation_sat17', 'Participation_sat18', 'Participation_sat19',\n",
    "                                   'Participation_act17', 'Participation_act18', 'Participation_act19']]\n",
    "                        \n",
    "\n",
    "change_in_par['Par_change_sat17to19'] = change_in_par['Participation_sat19'] - change_in_par['Participation_sat17']\n",
    "                                \n",
    "change_in_par['Par_change_act17to19'] = change_in_par['Participation_act19'] - change_in_par['Participation_act17']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_in_par.to_csv('../data/change_in_par_rate.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_in_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To view just the participation rate changes to see which states has the biggest increase / decrease in participation rate in each test\n",
    "\n",
    "change_in_par_cols = change_in_par.loc[:,['State', 'Par_change_sat17to19', 'Par_change_act17to19']]\n",
    "\n",
    "change_in_par_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_in_par.sort_values('State', ascending = False, inplace = True)\n",
    "\n",
    "change_in_par.plot(x='State', \n",
    "               y = ['Par_change_sat17to19',\n",
    "                    'Participation_sat17',\n",
    "                    'Par_change_act17to19',\n",
    "                    'Participation_act17'], color=['green','blue','red', 'salmon'], kind='barh', figsize=(10,18))\n",
    "\n",
    "plt.ylabel('State', fontsize = 14)\n",
    "plt.xlabel('Participation Rate', fontsize = 14)\n",
    "plt.title('Change in SAT & ACT Participation Rate from 2017 to 2019', fontsize = 16)\n",
    "objects = ('Change in SAT Participation Rate', 'SAT Participation Rate',\n",
    "           'Change in ACT Participation Rate', 'ACT Participation Rate')\n",
    "y_pos = np.arange(len(objects))\n",
    "# add the legend\n",
    "plt.legend(labels = objects, loc = 'lower left', framealpha = 0.5)\n",
    "\n",
    "plt.savefig('../charts/Barchart.jpg') #savefig must be done before plt.show()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretations\n",
    "\n",
    "Above bar chart shows that SAT participation rate has gone up as an overall since 2017, with very few States that have small decreases in their SAT participation rates. The opposite is true for ACT participation rate. The increase in SAT participation rate is the most notable in the States such as:\n",
    "1. Colorado, `+89%`\n",
    "2. Illinois, `+91%`\n",
    "3. West Virginia, `+85%`\n",
    "4. South Carolina, `+18%`\n",
    "5. Florida, `+17%`\n",
    "\n",
    "States with the biggest decrease in SAT participation rate from 2017 to 2019 are District of Columbia and Nevada. However, this decrease is small, at only `-6%` for each State.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key Takeaways\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above findings, there are a few States with notable differences increases and decreases in participation rates. Hence, more studies should be done on these States:\n",
    "\n",
    "1. Ohio\n",
    "3. illinois\n",
    "4. Oklahoma\n",
    "5. West Virginia\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ohio state law requires districts and community schools to administer the state-funded ACT or SAT to all grade 11 students. This has resulted in an increase for participation for both ACT and SAT tests.\n",
    "\n",
    "Rhode Island has made SAT testing compulsory for all students. This was implemented between 2017 and 2018 and its effects can be seen in the SAT participation, from 71% in 2017 to 97% in 2018.\n",
    "\n",
    "Illinois, like Rhode Island, has also made SAT testing compulsory for all public high school juniors. This has caused an exponential incrase in SAT participation from 9% to 99%. The ACT partipation rate was halved during this period. It should be noted that this move by the Illinois State Board of Education opposed this decision and is awaiting the final outcome.\n",
    "\n",
    "In West Virginia, the participation for SAT has doubled from 14% to 28% while ACT saw a decrease by 5%. This can be attributed to the education department's implementation of the SAT School Day where high school students can take the SAT tests on an allocated school day rather than taking in on a weekend and usually at a test center which they do not school at.\n",
    "\n",
    "\n",
    "Another noteworthy State is Florida where participation is high for both tests, at 83% for SAT and 73 % for ACT in 2017. The participation rate then fell to 56% for SAT and 66% for ACT in 2018, only for SAT's participation to increase to 100% versus ACT's 54% in 2019.\n",
    "\n",
    "\n",
    "Between 2017 and 2018, 10 states (Colorado, Connecticut, Delaware, Idaho, Illinois, Maine, Michigan, New Hampshire, Rhode Island, and West Virginia) and the District of Columbia covered the cost of the SAT for all their public school students. Three years ago, only three states and the District of Columbia did so. This, and the implementation of the SAT School Day contributed to the overall 25% increase in SAT test-takers.\n",
    "\n",
    "As such, the SAT School Day and the cost subsidy of the SAT can be seen to greatly improve SAT participation rates.\n",
    "\n",
    "Another noteworthy State is Florida where participation is high for both tests, at 83% for SAT and 73 % for ACT in 2017. The participation rate then fell to 56% for SAT and 66% for ACT in 2018, only for SAT's participation to increase to 100% versus ACT's 54% in 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to create your README!\n",
    "\n",
    "**To-Do:** *If you combine your problem statement, data dictionary, brief summary of your analysis, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.* Don't forget to cite your data sources!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
