{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19dea624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import itertools \n",
    "import random\n",
    "random.seed(42)\n",
    "from random import shuffle\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input, InceptionResNetV2\n",
    "\n",
    "# connect to gpu\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711bbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541d24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(results):\n",
    "    plt.plot(results.history['loss'])\n",
    "    plt.plot(results.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train loss', 'val loss'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efaa368b",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "path='../signatures_full/train/forged'\n",
    "list_name =[]\n",
    "for root, dirs, files in os.walk(path):\n",
    "    list_name.extend(files)\n",
    "from collections import defaultdict\n",
    "#Does not raise KeyError. It provides a default value for the key that does not exists\n",
    "\n",
    "dic=defaultdict(list)\n",
    "\n",
    "\n",
    "for i in list_name:\n",
    "    filename,ext =os.path.splitext(i)\n",
    "    cat, group, img_index = filename.split('_')\n",
    "    dic[group].append(img_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b57c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sub_directory called forged_person inside the forged directory if folder does not exist\n",
    "directory = 'forged_person'\n",
    "parent_dir = '../datasets/signatures_full/test/forged'\n",
    "path = os.path.join(parent_dir, directory)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a71f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group every signature from each individual in one folder\n",
    "import shutil\n",
    "new_folder='../signatures_full/train/forged/forged_person'\n",
    "path='../signatures_full/train/forged'\n",
    "\n",
    "for i in dic:        \n",
    "        if not os.path.exists(os.path.join(new_folder,i)):\n",
    "            os.mkdir(os.path.join(new_folder,i))\n",
    "            for img in dic[i]:\n",
    "                old_image = os.path.join(path,'forgeries_{}_{}.png'.format(i,img))\n",
    "                new_image = r'{}.png'.format(img)\n",
    "                new_path =os.path.join(new_folder,i)\n",
    "\n",
    "                shutil.move(old_image,os.path.join(new_path,new_image)) #Recursively moves a file or directory to another location and returns the destination.\n",
    "                #If the destination directory already exists then src is moved inside that directory.\n",
    "                \n",
    "        else:\n",
    "            for img in dic[i]:\n",
    "                old_image = os.path.join(path,'forgeries_{}_{}.png'.format(i,img))\n",
    "                new_image = r'{}.png'.format(img)\n",
    "                new_path =os.path.join(new_folder,i)\n",
    "                print(new_path)\n",
    "                shutil.move(old_image,os.path.join(new_path,new_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfe4f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../signatures_full/train/genuine'\n",
    "list_name_2 =[]\n",
    "for root, dirs, files in os.walk(path):\n",
    "    list_name_2.extend(files)\n",
    "from collections import defaultdict\n",
    "\n",
    "dic_2=defaultdict(list)\n",
    "\n",
    "\n",
    "for i in list_name_2:\n",
    "    filename,ext =os.path.splitext(i)\n",
    "    cat, group, img_index = filename.split('_')\n",
    "    dic_2[group].append(img_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a740365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sub_directory called genuine_person inside the genuine directory\n",
    "directory = 'genuine_person'\n",
    "parent_dir = '../datasets/signatures_full/test/genuine'\n",
    "path = os.path.join(parent_dir, directory)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d749b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group every signature from each individual in one folder\n",
    "\n",
    "new_folder='../signatures_full/train/genuine_person'\n",
    "path='../signatures_full/train/genuine'\n",
    "\n",
    "for i in dic_2:        \n",
    "        if not os.path.exists(os.path.join(new_folder,i)):\n",
    "            os.mkdir(os.path.join(new_folder,i))\n",
    "            for img in dic_2[i]:\n",
    "                old_image = os.path.join(path,'original_{}_{}.png'.format(i,img))\n",
    "                new_image = r'{}.png'.format(img)\n",
    "                new_path =os.path.join(new_folder,i)\n",
    "\n",
    "                shutil.move(old_image,os.path.join(new_path,new_image))\n",
    "        else:\n",
    "            for img in dic_2[i]:\n",
    "                old_image = os.path.join(path,'original_{}_{}.png'.format(i,img))\n",
    "                new_image = r'{}.png'.format(img)\n",
    "                new_path =os.path.join(new_folder,i)\n",
    "                print(new_path)\n",
    "                shutil.move(old_image,os.path.join(new_path,new_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ebf6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39b57c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of different list of genuine signature images from a single person\n",
    "\n",
    "path = '../datasets/signatures_full/train/genuine/genuine_person'\n",
    "# create a list of directories containing signatures of each person\n",
    "dir_list_gen = next(os.walk(path))[1]  # root, folder, files\n",
    "# sort the list\n",
    "dir_list_gen.sort()\n",
    "# create an empty list\n",
    "orig_groups=[]\n",
    "for directory in dir_list_gen:\n",
    "    images = os.listdir(path+'/'+directory)\n",
    "    images.sort()\n",
    "    # list comprehension generating the file path of each img inside the dir\n",
    "    images = [path+'/'+directory+'/' + x for x in images]\n",
    "    orig_groups.append(images)  # appending the list inside the genuine list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f54e9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../datasets/signatures_full/train/genuine/genuine_person/11/1.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/10.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/11.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/12.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/13.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/14.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/15.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/16.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/17.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/18.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/19.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/2.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/20.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/3.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/4.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/5.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/6.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/7.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/8.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/9.png']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_groups[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04886a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forged signature lists\n",
    "path = '../datasets/signatures_full/train/forged/forged_person'\n",
    "\n",
    "dir_list_forg = sorted(os.listdir(path))\n",
    "dir_list_forg.sort()\n",
    "\n",
    "forg_groups = []\n",
    "for directory in dir_list_forg:\n",
    "    images = os.listdir(path+'/'+directory)\n",
    "    images.sort()\n",
    "    images = [path+'/'+directory+'/'+x for x in images]\n",
    "    forg_groups.append(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc5a06b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a633ef5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 55)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orig_groups), len(forg_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3405e3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]\n",
      "[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]\n"
     ]
    }
   ],
   "source": [
    "#check the number of signatures per individual. Both genuine and forged\n",
    "orig_lengths = [len(x) for x in orig_groups]\n",
    "forg_lengths = [len(x) for x in forg_groups]\n",
    "print(orig_lengths)\n",
    "print(forg_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50c5057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and validation\n",
    "#40 individuals for training and 15 for validation\n",
    "orig_train, orig_val = orig_groups[:40], orig_groups[40:]\n",
    "forg_train, forg_val = forg_groups[:40], forg_groups[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13f7f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the images will be converted to the same size before processing\n",
    "img_h, img_w = 150,150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffc3f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(orig_groups, forg_groups, batch_size = 32):\n",
    "    #Function to generate a batch of data with batch_size number of data points\n",
    "    #Half of the data points will be Genuine-Genuine pairs and half will be Genuine-Forged pairs\n",
    "    while True:\n",
    "        orig_pairs = []\n",
    "        forg_pairs = []\n",
    "        gen_gen_labels = []\n",
    "        gen_for_labels = []\n",
    "        all_pairs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Here we create pairs of Genuine-Genuine image names and Genuine-Forged image names\n",
    "        # For every person we have 20 genuine signatures, hence we have \n",
    "        # 20 choose 2 = 190 Genuine-Genuine image pairs for one person.\n",
    "        # To make Genuine-Forged pairs, we pair every Genuine signature of a person\n",
    "        # with 12 randomly sampled Forged signatures of the same person.\n",
    "        # Thus we make 20 * 12 = 240 Genuine-Forged image pairs for one person.\n",
    "        # In all we have 40 person's data in the training data.\n",
    "        # Total no. of Genuine-Genuine pairs = 40 * 190= 7600\n",
    "        # Total number of Genuine-Forged pairs = 40 * 240 = 9600\n",
    "        # Total no. of data points = 7600 + 9600 = 17200\n",
    "        for orig, forg in zip(orig_groups, forg_groups):\n",
    "            orig_pairs.extend(list(itertools.combinations(orig, 2)))\n",
    "            for i in range(len(forg)):\n",
    "                forg_pairs.extend(list(itertools.product(orig[i:i+1], random.sample(forg, 12))))\n",
    "        \n",
    "        # Label for Genuine-Genuine pairs is 1\n",
    "        # Label for Genuine-Forged pairs is 0\n",
    "        gen_gen_labels = [1]*len(orig_pairs)\n",
    "        gen_for_labels = [0]*len(forg_pairs)\n",
    "        \n",
    "        # Concatenate all the pairs together along with their labels and shuffle them\n",
    "        all_pairs = orig_pairs + forg_pairs\n",
    "        all_labels = gen_gen_labels + gen_for_labels\n",
    "        del orig_pairs, forg_pairs, gen_gen_labels, gen_for_labels\n",
    "        all_pairs, all_labels = shuffle(all_pairs, all_labels)\n",
    "        \n",
    "        # Note the lists above contain only the image names and\n",
    "        # actual images are loaded and yielded below in batches\n",
    "        # Below we prepare a batch of data points and yield the batch\n",
    "        # In each batch we load \"batch_size\" number of image pairs\n",
    "        # These images are then removed from the original set so that\n",
    "        # they are not added again in the next batch.\n",
    "            \n",
    "        k = 0\n",
    "        pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
    "        targets=np.zeros((batch_size,))\n",
    "        for ix, pair in enumerate(all_pairs):\n",
    "            img1 = cv2.imread(pair[0], 0)\n",
    "            img2 = cv2.imread(pair[1], 0)\n",
    "            img1 = cv2.resize(img1, (img_w, img_h))\n",
    "            img2 = cv2.resize(img2, (img_w, img_h))\n",
    "            img1 = np.array(img1, dtype = np.float64)\n",
    "            img2 = np.array(img2, dtype = np.float64)\n",
    "            img1 /= 255\n",
    "            img2 /= 255\n",
    "            img1 = img1[..., np.newaxis]\n",
    "            img2 = img2[..., np.newaxis]\n",
    "            pairs[0][k, :, :, :] = img1\n",
    "            pairs[1][k, :, :, :] = img2\n",
    "            targets[k] = all_labels[ix]\n",
    "            k += 1\n",
    "            if k == batch_size:\n",
    "                yield pairs, targets\n",
    "                k = 0\n",
    "                pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
    "                targets=np.zeros((batch_size,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecffafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    #Compute Euclidean Distance between two vectors\n",
    "    \n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a8f475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39070a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):          #contrastive_loss - This loss encourages the embedding to be close to each other for\n",
    "                                               #the samples of the same label and the embedding to be far apart at least\n",
    "                                               #by the margin constant for the samples of different labels\n",
    "\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79a443d5",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def create_pairs(orig_groups, forg_groups):\n",
    "    orig_pairs = []\n",
    "    forg_pairs = []\n",
    "    gen_gen_labels = []\n",
    "    gen_for_labels = []\n",
    "    all_pairs = []\n",
    "    all_labels = []\n",
    "        \n",
    "    # Here we create pairs of Genuine-Genuine image names and Genuine-Forged image names\n",
    "    # For every person we have 20 genuine signatures, hence we have \n",
    "    # 20 choose 2 = 190 Genuine-Genuine image pairs for one person.\n",
    "    # To make Genuine-Forged pairs, we pair every Genuine signature of a person\n",
    "    # with 12 randomly sampled Forged signatures of the same person.\n",
    "    # Thus we make 20 * 12 = 240 Genuine-Forged image pairs for one person.\n",
    "    # In all we have 40 person's data in the training data.\n",
    "    # Total no. of Genuine-Genuine pairs = 40 * 190= 7600\n",
    "    # Total number of Genuine-Forged pairs = 40 * 240 = 9600\n",
    "    # Total no. of data points = 7600 + 9600 = 17200\n",
    "    for orig, forg in zip(orig_groups, forg_groups):\n",
    "        orig_pairs.extend(list(itertools.combinations(orig, 2)))\n",
    "        for i in range(len(forg)):\n",
    "            forg_pairs.extend(list(itertools.product(orig[i:i+1], random.sample(forg, 12))))\n",
    "        \n",
    "    # Label for Genuine-Genuine pairs is 1\n",
    "    # Label for Genuine-Forged pairs is 0\n",
    "    gen_gen_labels = [1]*len(orig_pairs)\n",
    "    gen_for_labels = [0]*len(forg_pairs)\n",
    "        \n",
    "    # Concatenate all the pairs together along with their labels and shuffle them\n",
    "    all_pairs = orig_pairs + forg_pairs\n",
    "    all_labels = gen_gen_labels + gen_for_labels\n",
    "    \n",
    "    return (all_pairs, all_labels)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c477aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X_pairs, y_labels, batch_size):\n",
    "    \"\"\"\"Returns a batch of images for the model to consume\n",
    "    \n",
    "    Args:\n",
    "        X_pairs (tuple[str, str]): List of tuples with two image filepaths\n",
    "        y_labels (List[int]): List of labels for pairs, 1 for similar and 0 for dissimilar\n",
    "    \n",
    "    Yields:\n",
    "        tuple[(ndarray, ndarray), ndarray]\n",
    "    \"\"\"\n",
    "    total_pairs = len(y_labels)\n",
    "    while True:\n",
    "        batch = []\n",
    "        labels = []\n",
    "        for i, ((img_filename_1, img_filename_2), label) in enumerate(zip(X_pairs, y_labels)):\n",
    "            img_1 = cv2.imread(img_filename_1)\n",
    "            img_2 = cv2.imread(img_filename_2)\n",
    "            img_1 = preprocess_image_inception_keras(img_1)\n",
    "            img_2 = preprocess_image_inception_keras(img_2)\n",
    "            batch.append([img_1, img_2])\n",
    "            labels.append(label)\n",
    "            if (i + 1) % batch_size == 0 or (i + 1) == total_pairs:\n",
    "                result = np.array(batch, dtype=np.float32)\n",
    "                yield ([result[:, 0], result[:, 1]], np.array(labels, dtype=np.float32))\n",
    "                result = None\n",
    "                batch = []\n",
    "                labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9215ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_inception_keras(image_matrix):\n",
    "    X = np.array(image_matrix, dtype=np.float32)\n",
    "    return preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55187dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_pairs(orig_train, forg_train)\n",
    "X_val, y_val = create_pairs(orig_val, forg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ac43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28d22ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca20740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_shape, model_name, freeze_layers_until=None):\n",
    "    \"\"\"Get the base network to do the feature extract for the latent embedding\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): Shape of image tensor input\n",
    "        \n",
    "    Returns:\n",
    "        keras.models.Model\n",
    "    \"\"\"\n",
    "    input = Input(shape=input_shape)\n",
    "    model = model_name(weights='imagenet', input_tensor=input)\n",
    "    model.layers.pop()  # Remove classification layer\n",
    "\n",
    "    if freeze_layers_until:\n",
    "        assert freeze_layers_until in [l.name for l in model.layers]\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "            if type(layer) == 'BatchNormalization':\n",
    "                layer.momentum = 1.0\n",
    "            if layer.name == freeze_layers_until:\n",
    "                break\n",
    "\n",
    "    model = Model(inputs=[input], outputs=[model.layers[-1].output], name='embedding_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46a9e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    \"\"\"Compute classification accuracy with a fixed threshold on distances.\"\"\"\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47f8b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"Compute classification accuracy with a fixed threshold on distances.\"\"\"\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36992d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change these unless you know what you are doing\n",
    "IMAGE_SHAPE = (150, 150, 3)\n",
    "IMAGE_SIZE = IMAGE_SHAPE[:2]\n",
    "EVAL_PERCENT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa946d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72c351e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the Inception ResNet V2 model pretrained on image net\n",
    "# Freeze layers up to mixed_6a for faster training and less overfitting\n",
    "base_network = create_base_network(IMAGE_SHAPE, InceptionResNetV2, 'mixed_6a')\n",
    "\n",
    "# Create two inputs for both images from pairs\n",
    "input_a = Input(shape=IMAGE_SHAPE)\n",
    "input_b = Input(shape=IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "695c3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the same base_network created above to the two image inputs\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "# Get the distance between the two input images\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "# Create a model which takes in a pair of images and returns the distance\n",
    "model = Model([input_a, input_b], distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ada277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback functions to call after every epoch\n",
    "ckpt_dir = 'checkpoints'\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)\n",
    "ckpt_pattern = os.path.join(ckpt_dir, 'weights.{epoch:02d}-{val_loss:.5f}.hdf5')\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(ckpt_pattern,\n",
    "                    monitor='val_loss',\n",
    "                    save_best_only=True),\n",
    "    ReduceLROnPlateau('loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5937f725",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding_model (Functional)   (None, 1000)         55873736    ['input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['embedding_model[0][0]',        \n",
      "                                                                  'embedding_model[1][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 55,873,736\n",
      "Trainable params: 51,480,168\n",
      "Non-trainable params: 4,393,568\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "init_learning_rate = 0.0005\n",
    "rms = RMSprop(learning_rate=init_learning_rate)\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f133a3e2",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "537/537 [==============================] - 253s 423ms/step - loss: 0.0882 - accuracy: 0.8897 - val_loss: 0.5134 - val_accuracy: 0.4646 - lr: 5.0000e-04\n",
      "Epoch 2/20\n",
      "537/537 [==============================] - 224s 415ms/step - loss: 0.0584 - accuracy: 0.9208 - val_loss: 0.5544 - val_accuracy: 0.4453 - lr: 5.0000e-04\n",
      "Epoch 3/20\n",
      "537/537 [==============================] - 226s 422ms/step - loss: 0.0430 - accuracy: 0.9374 - val_loss: 0.5218 - val_accuracy: 0.5292 - lr: 5.0000e-04\n",
      "Epoch 4/20\n",
      "537/537 [==============================] - 226s 422ms/step - loss: 0.0669 - accuracy: 0.9175 - val_loss: 0.5293 - val_accuracy: 0.4557 - lr: 5.0000e-04\n",
      "Epoch 5/20\n",
      "537/537 [==============================] - 224s 416ms/step - loss: 0.0507 - accuracy: 0.9398 - val_loss: 0.5492 - val_accuracy: 0.5622 - lr: 5.0000e-04\n",
      "Epoch 6/20\n",
      "537/537 [==============================] - 223s 416ms/step - loss: 0.0298 - accuracy: 0.9614 - val_loss: 0.5452 - val_accuracy: 0.4579 - lr: 5.0000e-04\n",
      "Epoch 7/20\n",
      "537/537 [==============================] - 224s 416ms/step - loss: 0.0480 - accuracy: 0.9395 - val_loss: 0.5274 - val_accuracy: 0.5045 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "537/537 [==============================] - 225s 419ms/step - loss: 0.1406 - accuracy: 0.8482 - val_loss: 0.5409 - val_accuracy: 0.5131 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.8951\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "537/537 [==============================] - 222s 414ms/step - loss: 0.0879 - accuracy: 0.8951 - val_loss: 0.5534 - val_accuracy: 0.4507 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "537/537 [==============================] - 224s 417ms/step - loss: 0.1037 - accuracy: 0.8803 - val_loss: 0.5307 - val_accuracy: 0.5168 - lr: 2.5000e-04\n",
      "Epoch 11/20\n",
      "537/537 [==============================] - 226s 420ms/step - loss: 0.0787 - accuracy: 0.9161 - val_loss: 0.5301 - val_accuracy: 0.5107 - lr: 2.5000e-04\n",
      "Epoch 12/20\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9627\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "537/537 [==============================] - 225s 419ms/step - loss: 0.0330 - accuracy: 0.9627 - val_loss: 0.5521 - val_accuracy: 0.4841 - lr: 2.5000e-04\n",
      "Epoch 13/20\n",
      "537/537 [==============================] - 222s 414ms/step - loss: 0.0959 - accuracy: 0.9001 - val_loss: 0.5442 - val_accuracy: 0.4913 - lr: 1.2500e-04\n",
      "Epoch 14/20\n",
      "537/537 [==============================] - 223s 415ms/step - loss: 0.0604 - accuracy: 0.9361 - val_loss: 0.5419 - val_accuracy: 0.5006 - lr: 1.2500e-04\n",
      "Epoch 15/20\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9003\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "537/537 [==============================] - 224s 417ms/step - loss: 0.0931 - accuracy: 0.9003 - val_loss: 0.5553 - val_accuracy: 0.4420 - lr: 1.2500e-04\n",
      "Epoch 16/20\n",
      "537/537 [==============================] - 222s 414ms/step - loss: 0.0637 - accuracy: 0.9287 - val_loss: 0.5521 - val_accuracy: 0.4431 - lr: 6.2500e-05\n",
      "Epoch 17/20\n",
      "537/537 [==============================] - 224s 416ms/step - loss: 0.0759 - accuracy: 0.9168 - val_loss: 0.5539 - val_accuracy: 0.4431 - lr: 6.2500e-05\n",
      "Epoch 18/20\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.8478\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "537/537 [==============================] - 222s 414ms/step - loss: 0.1427 - accuracy: 0.8478 - val_loss: 0.5539 - val_accuracy: 0.4431 - lr: 6.2500e-05\n",
      "Epoch 19/20\n",
      "537/537 [==============================] - 224s 417ms/step - loss: 0.2766 - accuracy: 0.6968 - val_loss: 0.5542 - val_accuracy: 0.4431 - lr: 3.1250e-05\n",
      "Epoch 20/20\n",
      "537/537 [==============================] - 222s 413ms/step - loss: 0.1712 - accuracy: 0.8024 - val_loss: 0.5551 - val_accuracy: 0.4431 - lr: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(batch_generator(X_train, y_train, 32),\n",
    "          steps_per_epoch=len(X_train) // 32,\n",
    "          epochs=20,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=batch_generator(X_val, y_val, 32),\n",
    "          validation_steps=len(y_val) // 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f92ccf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0621c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "model.save(os.path.join(ckpt_dir, 'final_model.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5673f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1efe59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True),\n",
    "    # ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.000001, verbose=1),\n",
    "    ModelCheckpoint(\n",
    "        '../weights/inception_resnetv2-model-{epoch:02d}.h5', verbose=1, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "199b9839",
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding_model (Functional)   (None, 1000)         55873736    ['input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['embedding_model[0][0]',        \n",
      "                                                                  'embedding_model[1][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 55,873,736\n",
      "Trainable params: 51,480,168\n",
      "Non-trainable params: 4,393,568\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "init_learning_rate = 1e-3\n",
    "rms = RMSprop(learning_rate=init_learning_rate)\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d40fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(batch_generator(X_train, y_train, 32),\n",
    "                    steps_per_epoch=len(X_train) // 32,\n",
    "                    epochs=30,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=batch_generator(X_val, y_val, 32),\n",
    "                    validation_steps=len(y_val) // 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f082fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7bdebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
