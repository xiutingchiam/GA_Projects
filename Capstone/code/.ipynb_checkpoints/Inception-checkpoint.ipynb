{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "19dea624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools \n",
    "import random\n",
    "random.seed(42)\n",
    "from random import shuffle\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input, InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "efaa368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../signatures_full/train/forged'\n",
    "list_name =[]\n",
    "for root, dirs, files in os.walk(path):\n",
    "    list_name.extend(files)\n",
    "from collections import defaultdict\n",
    "#Does not raise KeyError. It provides a default value for the key that does not exists\n",
    "\n",
    "dic=defaultdict(list)\n",
    "\n",
    "\n",
    "for i in list_name:\n",
    "    filename,ext =os.path.splitext(i)\n",
    "    cat, group, img_index = filename.split('_')\n",
    "    dic[group].append(img_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a6d37562",
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: '../signatures_full/train/forged\\\\forged_person'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19756/541979883.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparent_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../signatures_full/train/forged'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: '../signatures_full/train/forged\\\\forged_person'"
     ]
    }
   ],
   "source": [
    "#create a sub_directory called forged_person inside the forged directory\n",
    "directory='forged_person'\n",
    "parent_dir='../signatures_full/train/forged'\n",
    "path = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a71f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group every signature from each individual in one folder\n",
    "import shutil\n",
    "new_folder='../signatures_full/train/forged/forged_person'\n",
    "path='../signatures_full/train/forged'\n",
    "\n",
    "for i in dic:        \n",
    "        if not os.path.exists(os.path.join(new_folder,i)):\n",
    "            os.mkdir(os.path.join(new_folder,i))\n",
    "            for img in dic[i]:\n",
    "                old_image = os.path.join(path,'forgeries_{}_{}.png'.format(i,img))\n",
    "                new_image = r'{}.png'.format(img)\n",
    "                new_path =os.path.join(new_folder,i)\n",
    "\n",
    "                shutil.move(old_image,os.path.join(new_path,new_image)) #Recursively moves a file or directory to another location and returns the destination.\n",
    "                #If the destination directory already exists then src is moved inside that directory.\n",
    "                \n",
    "        else:\n",
    "            for img in dic[i]:\n",
    "                old_image = os.path.join(path,'forgeries_{}_{}.png'.format(i,img))\n",
    "                new_image = r'{}.png'.format(img)\n",
    "                new_path =os.path.join(new_folder,i)\n",
    "                print(new_path)\n",
    "                shutil.move(old_image,os.path.join(new_path,new_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../signatures_full/train/genuine'\n",
    "list_name_2 =[]\n",
    "for root, dirs, files in os.walk(path):\n",
    "    list_name_2.extend(files)\n",
    "from collections import defaultdict\n",
    "\n",
    "dic_2=defaultdict(list)\n",
    "\n",
    "\n",
    "for i in list_name_2:\n",
    "    filename,ext =os.path.splitext(i)\n",
    "    cat, group, img_index = filename.split('_')\n",
    "    dic_2[group].append(img_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93217071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a sub_directory called genuine_person inside the genuine directory\n",
    "\n",
    "directory='genuine_person'\n",
    "parent_dir='../signatures_full/train/genuine'\n",
    "path = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d749b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group every signature from each individual in one folder\n",
    "\n",
    "new_folder='../signatures_full/train/genuine_person'\n",
    "path='../signatures_full/train/genuine'\n",
    "\n",
    "for i in dic_2:        \n",
    "        if not os.path.exists(os.path.join(new_folder,i)):\n",
    "            os.mkdir(os.path.join(new_folder,i))\n",
    "            for img in dic_2[i]:\n",
    "                old_image = os.path.join(path,'original_{}_{}.png'.format(i,img))\n",
    "                new_image = r'{}.png'.format(img)\n",
    "                new_path =os.path.join(new_folder,i)\n",
    "\n",
    "                shutil.move(old_image,os.path.join(new_path,new_image))\n",
    "        else:\n",
    "            for img in dic_2[i]:\n",
    "                old_image = os.path.join(path,'original_{}_{}.png'.format(i,img))\n",
    "                new_image = r'{}.png'.format(img)\n",
    "                new_path =os.path.join(new_folder,i)\n",
    "                print(new_path)\n",
    "                shutil.move(old_image,os.path.join(new_path,new_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ebf6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "39b57c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of different list of genuine signature images from a single person\n",
    "\n",
    "path = '../datasets/signatures_full/train/genuine/genuine_person'\n",
    "# create a list of directories containing signatures of each person\n",
    "dir_list_gen = next(os.walk(path))[1]  # root, folder, files\n",
    "# sort the list\n",
    "dir_list_gen.sort()\n",
    "# create an empty list\n",
    "orig_groups=[]\n",
    "for directory in dir_list_gen:\n",
    "    images = os.listdir(path+'/'+directory)\n",
    "    images.sort()\n",
    "    # list comprehension generating the file path of each img inside the dir\n",
    "    images = [path+'/'+directory+'/' + x for x in images]\n",
    "    orig_groups.append(images)  # appending the list inside the genuine list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8f54e9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../datasets/signatures_full/train/genuine/genuine_person/11/1.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/10.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/11.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/12.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/13.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/14.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/15.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/16.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/17.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/18.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/19.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/2.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/20.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/3.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/4.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/5.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/6.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/7.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/8.png',\n",
       " '../datasets/signatures_full/train/genuine/genuine_person/11/9.png']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_groups[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "04886a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forged signature lists\n",
    "path = '../datasets/signatures_full/train/forged/forged_person'\n",
    "\n",
    "dir_list_forg = sorted(os.listdir(path))\n",
    "dir_list_forg.sort()\n",
    "\n",
    "forg_groups = []\n",
    "for directory in dir_list_forg:\n",
    "    images = os.listdir(path+'/'+directory)\n",
    "    images.sort()\n",
    "    images = [path+'/'+directory+'/'+x for x in images]\n",
    "    forg_groups.append(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc5a06b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a633ef5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 55)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orig_groups), len(forg_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3405e3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]\n",
      "[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]\n"
     ]
    }
   ],
   "source": [
    "#check the number of signatures per individual. Both genuine and forged\n",
    "orig_lengths = [len(x) for x in orig_groups]\n",
    "forg_lengths = [len(x) for x in forg_groups]\n",
    "print(orig_lengths)\n",
    "print(forg_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "50c5057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and validation\n",
    "#40 individuals for training and 15 for validation\n",
    "orig_train, orig_val = orig_groups[:40], orig_groups[40:]\n",
    "forg_train, forg_val = forg_groups[:40], forg_groups[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "13f7f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the images will be converted to the same size before processing\n",
    "img_h, img_w = 155,220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ffc3f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(orig_groups, forg_groups, batch_size = 32):\n",
    "    #Function to generate a batch of data with batch_size number of data points\n",
    "    #Half of the data points will be Genuine-Genuine pairs and half will be Genuine-Forged pairs\n",
    "    while True:\n",
    "        orig_pairs = []\n",
    "        forg_pairs = []\n",
    "        gen_gen_labels = []\n",
    "        gen_for_labels = []\n",
    "        all_pairs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Here we create pairs of Genuine-Genuine image names and Genuine-Forged image names\n",
    "        # For every person we have 20 genuine signatures, hence we have \n",
    "        # 20 choose 2 = 190 Genuine-Genuine image pairs for one person.\n",
    "        # To make Genuine-Forged pairs, we pair every Genuine signature of a person\n",
    "        # with 12 randomly sampled Forged signatures of the same person.\n",
    "        # Thus we make 20 * 12 = 240 Genuine-Forged image pairs for one person.\n",
    "        # In all we have 40 person's data in the training data.\n",
    "        # Total no. of Genuine-Genuine pairs = 40 * 190= 7600\n",
    "        # Total number of Genuine-Forged pairs = 40 * 240 = 9600\n",
    "        # Total no. of data points = 7600 + 9600 = 17200\n",
    "        for orig, forg in zip(orig_groups, forg_groups):\n",
    "            orig_pairs.extend(list(itertools.combinations(orig, 2)))\n",
    "            for i in range(len(forg)):\n",
    "                forg_pairs.extend(list(itertools.product(orig[i:i+1], random.sample(forg, 12))))\n",
    "        \n",
    "        # Label for Genuine-Genuine pairs is 1\n",
    "        # Label for Genuine-Forged pairs is 0\n",
    "        gen_gen_labels = [1]*len(orig_pairs)\n",
    "        gen_for_labels = [0]*len(forg_pairs)\n",
    "        \n",
    "        # Concatenate all the pairs together along with their labels and shuffle them\n",
    "        all_pairs = orig_pairs + forg_pairs\n",
    "        all_labels = gen_gen_labels + gen_for_labels\n",
    "        del orig_pairs, forg_pairs, gen_gen_labels, gen_for_labels\n",
    "        all_pairs, all_labels = shuffle(all_pairs, all_labels)\n",
    "        \n",
    "        # Note the lists above contain only the image names and\n",
    "        # actual images are loaded and yielded below in batches\n",
    "        # Below we prepare a batch of data points and yield the batch\n",
    "        # In each batch we load \"batch_size\" number of image pairs\n",
    "        # These images are then removed from the original set so that\n",
    "        # they are not added again in the next batch.\n",
    "            \n",
    "        k = 0\n",
    "        pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
    "        targets=np.zeros((batch_size,))\n",
    "        for ix, pair in enumerate(all_pairs):\n",
    "            img1 = cv2.imread(pair[0], 0)\n",
    "            img2 = cv2.imread(pair[1], 0)\n",
    "            img1 = cv2.resize(img1, (img_w, img_h))\n",
    "            img2 = cv2.resize(img2, (img_w, img_h))\n",
    "            img1 = np.array(img1, dtype = np.float64)\n",
    "            img2 = np.array(img2, dtype = np.float64)\n",
    "            img1 /= 255\n",
    "            img2 /= 255\n",
    "            img1 = img1[..., np.newaxis]\n",
    "            img2 = img2[..., np.newaxis]\n",
    "            pairs[0][k, :, :, :] = img1\n",
    "            pairs[1][k, :, :, :] = img2\n",
    "            targets[k] = all_labels[ix]\n",
    "            k += 1\n",
    "            if k == batch_size:\n",
    "                yield pairs, targets\n",
    "                k = 0\n",
    "                pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
    "                targets=np.zeros((batch_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ecffafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    #Compute Euclidean Distance between two vectors\n",
    "    \n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2a8f475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "39070a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):          #contrastive_loss - This loss encourages the embedding to be close to each other for\n",
    "                                               #the samples of the same label and the embedding to be far apart at least\n",
    "                                               #by the margin constant for the samples of different labels\n",
    "\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "79a443d5",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def create_pairs(orig_groups, forg_groups):\n",
    "    orig_pairs = []\n",
    "    forg_pairs = []\n",
    "    gen_gen_labels = []\n",
    "    gen_for_labels = []\n",
    "    all_pairs = []\n",
    "    all_labels = []\n",
    "        \n",
    "    # Here we create pairs of Genuine-Genuine image names and Genuine-Forged image names\n",
    "    # For every person we have 20 genuine signatures, hence we have \n",
    "    # 20 choose 2 = 190 Genuine-Genuine image pairs for one person.\n",
    "    # To make Genuine-Forged pairs, we pair every Genuine signature of a person\n",
    "    # with 12 randomly sampled Forged signatures of the same person.\n",
    "    # Thus we make 20 * 12 = 240 Genuine-Forged image pairs for one person.\n",
    "    # In all we have 40 person's data in the training data.\n",
    "    # Total no. of Genuine-Genuine pairs = 40 * 190= 7600\n",
    "    # Total number of Genuine-Forged pairs = 40 * 240 = 9600\n",
    "    # Total no. of data points = 7600 + 9600 = 17200\n",
    "    for orig, forg in zip(orig_groups, forg_groups):\n",
    "        orig_pairs.extend(list(itertools.combinations(orig, 2)))\n",
    "        for i in range(len(forg)):\n",
    "            forg_pairs.extend(list(itertools.product(orig[i:i+1], random.sample(forg, 12))))\n",
    "        \n",
    "    # Label for Genuine-Genuine pairs is 1\n",
    "    # Label for Genuine-Forged pairs is 0\n",
    "    gen_gen_labels = [1]*len(orig_pairs)\n",
    "    gen_for_labels = [0]*len(forg_pairs)\n",
    "        \n",
    "    # Concatenate all the pairs together along with their labels and shuffle them\n",
    "    all_pairs = orig_pairs + forg_pairs\n",
    "    all_labels = gen_gen_labels + gen_for_labels\n",
    "    \n",
    "    return (all_pairs, all_labels)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "55187dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_pairs(orig_train, forg_train)\n",
    "X_val, y_val = create_pairs(orig_val, forg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f2ac43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "28d22ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ca20740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_shape, freeze_layers_until=None):\n",
    "    \"\"\"Get the base network to do the feature extract for the latent embedding\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): Shape of image tensor input\n",
    "        \n",
    "    Returns:\n",
    "        keras.models.Model\n",
    "    \"\"\"\n",
    "    input = Input(shape=input_shape)\n",
    "    inception = InceptionResNetV2(weights='imagenet', input_tensor=input)\n",
    "    inception.layers.pop()  # Remove classification layer\n",
    "\n",
    "    if freeze_layers_until:\n",
    "        assert freeze_layers_until in [l.name for l in inception.layers]\n",
    "        for layer in inception.layers:\n",
    "            layer.trainable = False\n",
    "            if type(layer) == 'BatchNormalization':\n",
    "                layer.momentum = 1.0\n",
    "            if layer.name == freeze_layers_until:\n",
    "                break\n",
    "\n",
    "    model = Model(inputs=[input], outputs=[inception.layers[-1].output], name='embedding_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "46a9e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    \"\"\"Compute classification accuracy with a fixed threshold on distances.\"\"\"\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "47f8b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"Compute classification accuracy with a fixed threshold on distances.\"\"\"\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "72c351e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IMAGE_SHAPE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19756/1277719625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Grab the Inception ResNet V2 model pretrained on image net\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Freeze layers up to mixed_6a for faster training and less overfitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbase_network\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_base_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMAGE_SHAPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mixed_6a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Create two inputs for both images from pairs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'IMAGE_SHAPE' is not defined"
     ]
    }
   ],
   "source": [
    "# Grab the Inception ResNet V2 model pretrained on image net\n",
    "# Freeze layers up to mixed_6a for faster training and less overfitting\n",
    "base_network = create_base_network(IMAGE_SHAPE, 'mixed_6a')\n",
    "\n",
    "# Create two inputs for both images from pairs\n",
    "input_a = Input(shape=IMAGE_SHAPE)\n",
    "input_b = Input(shape=IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the same base_network created above to the two image inputs\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "# Get the distance between the two input images\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "# Create a model which takes in a pair of images and returns the distance\n",
    "model = Model([input_a, input_b], distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ada277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback functions to call after every epoch\n",
    "ckpt_dir = 'checkpoints'\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)\n",
    "ckpt_pattern = os.path.join(ckpt_dir, 'weights.{epoch:03d}-{val_loss:.5f}.hdf5')\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(ckpt_pattern,\n",
    "                    monitor='val_loss',\n",
    "                    save_best_only=True),\n",
    "    ReduceLROnPlateau('loss', factor=0.5, patience=3, verbose=1, min_lr=1e-7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937f725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133a3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92ccf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7bdebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eacd2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bec715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e5622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "15e0e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X_pairs, y_labels, batch_size):\n",
    "    \"\"\"\"Returns a batch of images for the model to consume\n",
    "    \n",
    "    Args:\n",
    "        X_pairs (tuple[str, str]): List of tuples with two image filepaths\n",
    "        y_labels (List[int]): List of labels for pairs, 1 for similar and 0 for dissimilar\n",
    "    \n",
    "    Yields:\n",
    "        tuple[(ndarray, ndarray), ndarray]\n",
    "    \"\"\"\n",
    "    total_pairs = len(y_labels)\n",
    "    while True:\n",
    "        batch = []\n",
    "        labels = []\n",
    "        for i, ((img_filename_1, img_filename_2), label) in enumerate(zip(X_pairs, y_labels)):\n",
    "            img_1 = get_and_cache_image(img_filename_1)\n",
    "            img_2 = get_and_cache_image(img_filename_2)\n",
    "            batch.append([img_1, img_2])\n",
    "            labels.append(label)\n",
    "            if (i + 1) % batch_size == 0 or (i + 1) == total_pairs:\n",
    "                result = np.array(batch, dtype=np.float32)\n",
    "                yield ([result[:, 0], result[:, 1]], np.array(labels, dtype=np.float32))\n",
    "                result = None\n",
    "                batch = []\n",
    "                labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2af5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "margin = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd1318fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs (x, y):\n",
    "    num_classes = max(y) + 1\n",
    "    image_indices = [np.where(y == i) for i in range(num_classes)]\n",
    "    \n",
    "    pairs = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx1 in range(len(x)):\n",
    "        # add a matching example\n",
    "        x1 = x[idx1]\n",
    "        label1 = y[idx1]\n",
    "        idx2 = random.choice(image_indices[label1])\n",
    "        x2 = x[idx2]\n",
    "\n",
    "        pairs += [[x1, x2]]\n",
    "        labels += [1]\n",
    "\n",
    "        # add a non-matching example\n",
    "        label2 = random.randint(0, num_classes - 1)\n",
    "        while label2 == label1:\n",
    "            label2 = random.randint(0, num_classes - 1)\n",
    "\n",
    "        idx2 = random.choice(image_indices[label2])\n",
    "        x2 = x[idx2]\n",
    "\n",
    "        pairs += [[x1, x2]]\n",
    "        labels += [0]\n",
    "\n",
    "    return np.array(pairs), np.array(labels).astype(\"float32\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c477aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X_pairs, y_labels, batch_size):\n",
    "    \"\"\"\"Returns a batch of images for the model to consume\n",
    "    \n",
    "    Args:\n",
    "        X_pairs (tuple[str, str]): List of tuples with two image filepaths\n",
    "        y_labels (List[int]): List of labels for pairs, 1 for similar and 0 for dissimilar\n",
    "    \n",
    "    Yields:\n",
    "        tuple[(ndarray, ndarray), ndarray]\n",
    "    \"\"\"\n",
    "    total_pairs = len(y_labels)\n",
    "    while True:\n",
    "        batch = []\n",
    "        labels = []\n",
    "        for i, ((img_filename_1, img_filename_2), label) in enumerate(zip(X_pairs, y_labels)):\n",
    "            img_1 = get_and_cache_image(img_filename_1)\n",
    "            img_2 = get_and_cache_image(img_filename_2)\n",
    "            img_1 = preprocess_image_inception_keras(img_1)\n",
    "            img_2 = preprocess_image_inception_keras(img_2)\n",
    "            batch.append([img_1, img_2])\n",
    "            labels.append(label)\n",
    "            if (i + 1) % batch_size == 0 or (i + 1) == total_pairs:\n",
    "                result = np.array(batch, dtype=np.float32)\n",
    "                yield ([result[:, 0], result[:, 1]], np.array(labels, dtype=np.float32))\n",
    "                result = None\n",
    "                batch = []\n",
    "                labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1045792e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19756/3080917006.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mgenuine_img_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mforged_img_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k, counts)\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0mrandbelow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m21\u001b[0m        \u001b[1;31m# size of a small set minus size of an empty list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "orig_pairs = []\n",
    "forg_pairs = []\n",
    "gen_gen_labels = []\n",
    "gen_for_labels = []\n",
    "all_pairs = []\n",
    "all_labels = []\n",
    "    \n",
    "for gen, forg in zip(genuine_img_path, forged_img_path):\n",
    "        genuine_img_path.extend(list(itertools.combinations(gen, 2)))\n",
    "        for i in range(len(forg)):\n",
    "            forged_img_path.extend(list(itertools.product(gen[i:i+1], random.sample(forg, 20))))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed09fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "178efcc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itertools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19756/3694032324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_pairs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenuine_img_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforged_img_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19756/2024462463.py\u001b[0m in \u001b[0;36mcreate_pairs\u001b[1;34m(orig_groups, forg_groups)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_groups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforg_groups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0morig_pairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 forg_pairs.extend(list(itertools.product(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'itertools' is not defined"
     ]
    }
   ],
   "source": [
    "results = create_pairs(genuine_img_path, forged_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1ca7591",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19756/4170858684.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f39635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ea028",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "features_forged = []\n",
    "features_real = []\n",
    "features_anchor = []\n",
    "features_dict = {}\n",
    "forged_img_path = []\n",
    "genuine_img_path = []\n",
    "anchhor_img_path = []\n",
    "anchor = 0\n",
    "labels = []  # forged: 0 and real: 1\n",
    "\n",
    "for folder in os.listdir(\"../datasets/signatures_full/train/forged/forged_person\"):\n",
    "    print(\"Searching folder {}\".format(folder))\n",
    "    # forged images\n",
    "    for sub in os.listdir(\"../datasets/signatures_full/train/forged/forged_person/\"+folder):\n",
    "        f = \"../datasets/signatures_full/train/forged/forged_person/\" + folder + \"/\" + sub\n",
    "        img = load_img(f, color_mode='grayscale', target_size=(150, 150))\n",
    "        features.append(img_to_array(img))\n",
    "        sub = 'forged_'+folder+'_'+sub\n",
    "        features_dict[sub] = (img, 0)\n",
    "        features_forged.append(img)\n",
    "        labels.append(0)  # forged\n",
    "        print(\"Adding {} with label 0\".format(f))\n",
    "        forged_img_path.append(f)\n",
    "for folder in os.listdir(\"../datasets/signatures_full/train/genuine/genuine_person\"):\n",
    "    for sub in os.listdir(\"../datasets/signatures_full/train/genuine/genuine_person/\"+folder):\n",
    "        result = sub.split('.')\n",
    "        anchor = int(result[0])\n",
    "        f = \"../datasets/signatures_full/train/genuine/genuine_person/\" + folder + \"/\" + sub\n",
    "        img = load_img(f, color_mode='grayscale', target_size=(150, 150))\n",
    "        features.append(img_to_array(img))\n",
    "        sub = 'genuine_'+folder+'_'+sub\n",
    "        features_dict[sub] = (img, 1)\n",
    "        features_real.append(img)\n",
    "        genuine_img_path.append(f)\n",
    "        labels.append(1)  # genuine        \n",
    "        if anchor < 20:\n",
    "            anchor += 1\n",
    "            anchor_f = \"../datasets/signatures_full/train/genuine/genuine_person/\" + folder + \"/\" + str(anchor) + '.png'\n",
    "            anchor_img = load_img(anchor_f, color_mode='grayscale', target_size=(150, 150))\n",
    "            features_anchor.append(anchor_img)\n",
    "            anchor_img_path.append(anchor_f)\n",
    "        else:\n",
    "            anchor = 1\n",
    "            anchor_f = \"../datasets/signatures_full/train/genuine/genuine_person/\" + folder + \"/\" + str(anchor) + '.png'\n",
    "            anchor_img = load_img(anchor_f, color_mode='grayscale', target_size=(150, 150))\n",
    "            features_anchor.append(anchor_img)\n",
    "            anY_img_path.append(anchor_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
